{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8891c7ce",
   "metadata": {
    "id": "8891c7ce",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "oXsIvnalrsWb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15674,
     "status": "ok",
     "timestamp": 1710546572485,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "oXsIvnalrsWb",
    "outputId": "0151a63a-c493-4fc2-f000-41be2efd32c2"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0ff7e4-cf5e-4586-a1f7-eab01ae63a15",
   "metadata": {
    "id": "8e0ff7e4-cf5e-4586-a1f7-eab01ae63a15"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os # read and manipulate local files\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score as f1_score_report\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow.keras as ks\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imgaug import augmenters as iaa # elastic_deformation\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Dense, BatchNormalization, Concatenate, GlobalAveragePooling2D\n",
    "\n",
    "# hide wornings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "################################################################################################\n",
    "# SETTING F1 SCORE\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "f1_score = F1Score(num_classes=4, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PMuxPpz9GjaY",
   "metadata": {
    "id": "PMuxPpz9GjaY"
   },
   "source": [
    "## Setting the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f806ed-e9db-4199-b7ee-c2fa11bd0dee",
   "metadata": {
    "id": "33f806ed-e9db-4199-b7ee-c2fa11bd0dee"
   },
   "outputs": [],
   "source": [
    "model_name = 'original_vit_v2'#'Xception'#'DenseNet121'#    'InceptionV3'##  'MobileNet', 'Xception', ensemble2, ensemble3, 'parallel_vit'\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "## SEETING THE PATHS\n",
    "PATH_TO_CODE =''\n",
    "# PATH_TO_CODE ='/content/drive/MyDrive/TRIAL_v1/classification'\n",
    "sys.path.append(PATH_TO_CODE)\n",
    "# DATASET_PATH = r'/content/drive/MyDrive/TRIAL_v1/classification/data44_resized_splited'\n",
    "DATASET_PATH = r'data44_resized_splited'\n",
    "DATASET_PATH_TRAIN = os.path.join(DATASET_PATH, 'train')\n",
    "DATASET_PATH_TEST = os.path.join(DATASET_PATH, 'test')\n",
    "\n",
    "\n",
    "PATH_TO_SAVE_RESULT = os.path.join(PATH_TO_CODE, 'saved_outputs_all_augment', model_name)\n",
    "PATH_BEST_SAVE_WEIGHT = os.path.join(PATH_TO_SAVE_RESULT,model_name+'_saved_weights')\n",
    "PATH_TO_SAVE_MODEL = os.path.join(PATH_TO_SAVE_RESULT, 'saved_models')\n",
    "PATH_SAVE_HISTORY = os.path.join(PATH_TO_SAVE_RESULT,model_name+'_training_history.csv')\n",
    "PATH_SAVE_TIME = os.path.join(PATH_TO_SAVE_RESULT, model_name+'_training_time.csv')\n",
    "\n",
    "\n",
    "if not os.path.exists(PATH_TO_SAVE_RESULT):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(PATH_TO_SAVE_RESULT)\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200\n",
    "ORIGINAL_IMAGE_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "COLOR_CHANNEL = 3\n",
    "\n",
    "RESIZE_SHAPE = (128, 128)\n",
    "MODEL_INPUT_SIZE = (RESIZE_SHAPE[0], RESIZE_SHAPE[1], COLOR_CHANNEL)\n",
    "\n",
    "VALIDATION_SPLIT= 0.3\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 68\n",
    "\n",
    "################################################################################################\n",
    "AUGMENT = True\n",
    "AUGMENT_TYPE = 'all' #'all'## basic, advanced,\n",
    "################################################################################################\n",
    "\n",
    "SAVE_RESULTS = True\n",
    "SHOW_RESULTS = True\n",
    "\n",
    "################################################################################################\n",
    "# Setting the seed\n",
    "SEED  = 123\n",
    "RNG = np.random.default_rng(SEED) # Random number generator\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "################################################################################################\n",
    "# Checkpoint parameters\n",
    "SCORE_TO_MONITOR = 'val_f1_score' # Score that checkpoints monitor during training\n",
    "SCORE_OBJECTIVE  = 'max'          # 'max' or 'min', specifies whether the objective is to maximize the score or minimize it.\n",
    "\n",
    "\n",
    "\n",
    "PATIENCE_EARLY_STOP = 12 # With no improvement in Loss, will stop training\n",
    "\n",
    "# # Checkpoint parameters\n",
    "REDUCTION_FACTOR = 0.5            # Factor which lr will be reduced with at plateau\n",
    "PATIENCE_LR_REDUCE=3      # Number of epochs with no improvement after which learning rate will be reduced\n",
    "COOLDOWN_EPOCHS  = 2              # How many epochs to wait after learning rate reduction before it can be reduced again\n",
    "MIN_LR = 1e-9\n",
    "INITIAL_LR =  0.0001 # with 0.001 got 99 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc029c0-dfb5-4571-a579-7fe7ca89cc2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1710546580214,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "5cc029c0-dfb5-4571-a579-7fe7ca89cc2a",
    "outputId": "43f824c2-c032-4d86-ab37-f4d842820b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_PATH data44_resized_splited\n",
      "DATASET_PATH_TRAIN data44_resized_splited\\train\n",
      "DATASET_PATH_TEST data44_resized_splited\\test\n",
      "PATH_SAVE_TIME  saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_training_time.csv\n",
      "PATH_SAVE_HISTORY saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_training_history.csv\n",
      "PATH_TO_SAVE_RESULT saved_outputs_all_augment\\original_vit_v2\n",
      "PATH_BEST_SAVE_WEIGHT saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\n",
      "PATH_TO_SAVE_MODEL saved_outputs_all_augment\\original_vit_v2\\saved_models\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET_PATH\", DATASET_PATH)\n",
    "print(\"DATASET_PATH_TRAIN\", DATASET_PATH_TRAIN)\n",
    "print(\"DATASET_PATH_TEST\", DATASET_PATH_TEST)\n",
    "\n",
    "print(\"PATH_SAVE_TIME \", PATH_SAVE_TIME )\n",
    "print(\"PATH_SAVE_HISTORY\", PATH_SAVE_HISTORY)\n",
    "print(\"PATH_TO_SAVE_RESULT\",PATH_TO_SAVE_RESULT)\n",
    "print(\"PATH_BEST_SAVE_WEIGHT\", PATH_BEST_SAVE_WEIGHT)\n",
    "print(\"PATH_TO_SAVE_MODEL\", PATH_TO_SAVE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae2d29-d089-412a-88a5-7b5017dee4f8",
   "metadata": {
    "id": "60ae2d29-d089-412a-88a5-7b5017dee4f8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f4e78e-2715-4ec6-b86d-a032075066a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1710546580214,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "d0f4e78e-2715-4ec6-b86d-a032075066a9",
    "outputId": "e1dcafe6-bd5c-4851-806d-5d2ea9ff8434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mahri\\AppData\\Local\\Temp\\ipykernel_18116\\984659479.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU Available:  True\n",
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30676387-9bdf-4015-83e8-db47734137d4",
   "metadata": {
    "id": "30676387-9bdf-4015-83e8-db47734137d4"
   },
   "source": [
    "## Image Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dada5c-1141-4914-96bd-a8ff36749e6d",
   "metadata": {
    "id": "69dada5c-1141-4914-96bd-a8ff36749e6d"
   },
   "source": [
    "### ElasticTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cce2108f-7c14-40de-b590-d7e14856ae64",
   "metadata": {
    "id": "cce2108f-7c14-40de-b590-d7e14856ae64"
   },
   "outputs": [],
   "source": [
    "# Define an augmentation pipeline\n",
    "# Alpha parameter controls the intensity of the deformation\n",
    "# Sigma controls the smoothness of the deformation field.\n",
    "aug = iaa.Sequential([\n",
    "    iaa.ElasticTransformation(alpha=10, sigma=5)  # Apply elastic transformations , sigma=1\n",
    "])\n",
    "\n",
    "def elastic_deformation(image):\n",
    "    image_aug = aug(image=image)\n",
    "    return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e823091d-ce18-4444-845c-8a9bc459800a",
   "metadata": {
    "id": "e823091d-ce18-4444-845c-8a9bc459800a"
   },
   "outputs": [],
   "source": [
    "# Defining a function for creating the generators with given augmentation type\n",
    "def create_generators(dataset_path_train=DATASET_PATH_TRAIN,\n",
    "                      dataset_path_test=DATASET_PATH_TEST,\n",
    "                      valid_ratio=VALIDATION_SPLIT,\n",
    "                      augment= False,\n",
    "                      augment_type='basic'):\n",
    "\n",
    "    # If augmentation is True, apply data augmentation. Otherwise, only rescale.\n",
    "    if augment:\n",
    "        if augment_type == 'all':\n",
    "            datagen = ImageDataGenerator(\n",
    "                rescale=1./255, # Normalize images\n",
    "                validation_split=valid_ratio,  # Split ratio for validation set\n",
    "\n",
    "                # Geometric Transformations\n",
    "                rotation_range=10,  # degrees\n",
    "                width_shift_range=0.2,  # fraction of total width\n",
    "                height_shift_range=0.2,  # fraction of total height\n",
    "                shear_range=0.2,  # shear angle in counter-clockwise direction as radians\n",
    "                zoom_range=0.2,  # zoom range for random zoom\n",
    "                horizontal_flip=True,  # randomly flip images horizontally\n",
    "                # vertical_flip=True,  # randomly flip images vertically\n",
    "\n",
    "                # Pixel-Level Transformations\n",
    "                brightness_range=[0.8, 1.1],  # range for picking a brightness shift value\n",
    "                channel_shift_range=0.2,  # range for random channel shifts\n",
    "\n",
    "                # # Advanced functions\n",
    "                # preprocessing_function=elastic_deformation\n",
    "            )\n",
    "        elif augment_type == 'basic':\n",
    "            datagen = ImageDataGenerator(\n",
    "                rescale=1./255, # Normalize images\n",
    "                validation_split=valid_ratio,  # Split ratio for validation set\n",
    "\n",
    "                # Geometric Transformations\n",
    "                # rotation_range=10,  # degrees\n",
    "                zoom_range=0.2,  # zoom range for random zoom\n",
    "                # vertical_flip=True,  # randomly flip images vertically\n",
    "                horizontal_flip=True,  # randomly flip images horizontally\n",
    "            )\n",
    "    else:\n",
    "        # No augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            validation_split=valid_ratio,  # Split ratio for validation set\n",
    "            rescale=1./255, # Normalize images\n",
    "        )\n",
    "\n",
    "    # Create training generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        dataset_path_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seed = SEED,\n",
    "        class_mode=\"categorical\",  # Use \"categorical\" for multi-class classification\n",
    "        target_size=RESIZE_SHAPE,  # Adjust target size based on your model requirements\n",
    "        shuffle = True,\n",
    "        color_mode = 'rgb',\n",
    "        subset='training'  # Specify subset as 'training'\n",
    "    )\n",
    "\n",
    "    # Create validation generator\n",
    "    valid_generator = datagen.flow_from_directory(\n",
    "        dataset_path_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seed = SEED,\n",
    "        class_mode=\"categorical\",  # Use \"categorical\" for multi-class classification\n",
    "        target_size=RESIZE_SHAPE,  # Adjust target size based on your model requirements\n",
    "        shuffle = True,\n",
    "        color_mode = 'rgb',\n",
    "        subset='validation'  # Specify subset as 'validation'\n",
    "    )\n",
    "\n",
    "    # For the test set, assuming no augmentation, just rescaling\n",
    "    test_datagen = ImageDataGenerator(\n",
    "                rescale=1./255# Normalize images\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        dataset_path_test,\n",
    "        class_mode=\"categorical\",  # Use \"categorical\" for multi-class classification\n",
    "        target_size=RESIZE_SHAPE,  # Adjust target size based on your model requirements\n",
    "        seed = SEED,\n",
    "        shuffle = False,\n",
    "        color_mode = 'rgb',\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "    return train_generator, valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "269c38da-a92b-47d1-918c-3b19f84aa19c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13301,
     "status": "ok",
     "timestamp": 1710546593510,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "269c38da-a92b-47d1-918c-3b19f84aa19c",
    "outputId": "84016ace-2739-473f-9cc1-20c2fa18bb0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3324 images belonging to 4 classes.\n",
      "Found 1421 images belonging to 4 classes.\n",
      "Found 1187 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating the generators using functions\n",
    "train_generator, valid_generator, test_generator = create_generators(dataset_path_train=DATASET_PATH_TRAIN,\n",
    "                                                                     dataset_path_test = DATASET_PATH_TEST,\n",
    "                                                                     augment=AUGMENT,\n",
    "                                                                     augment_type = AUGMENT_TYPE,\n",
    "                                                                     valid_ratio = VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a-w71u59zsyE",
   "metadata": {
    "id": "a-w71u59zsyE",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2EqjQhpCzut7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "executionInfo": {
     "elapsed": 46436,
     "status": "ok",
     "timestamp": 1710546639943,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "2EqjQhpCzut7",
    "outputId": "e3900d1b-0b6c-4c65-fa84-da6e351d6453"
   },
   "outputs": [],
   "source": [
    "# def plot_images(images, labels, classes=None):\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     for i in range(15):\n",
    "#         plt.subplot(5, 5, i + 1)\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#         plt.grid(False)\n",
    "#         plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "\n",
    "#         # If class labels are provided, add them to the subplot\n",
    "#         if classes is not None:\n",
    "#             label = classes[np.argmax(labels[i])]\n",
    "#             plt.xlabel(label)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# train_images, train_labels = next(train_generator)  # Fetch a batch of images and labels\n",
    "\n",
    "\n",
    "# plot_images(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ca5e3-a160-4ee9-a451-3041c841fad9",
   "metadata": {
    "id": "da5ca5e3-a160-4ee9-a451-3041c841fad9"
   },
   "source": [
    "## Essential functions (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a25f3325-61a1-4d40-9672-f853c6f0d092",
   "metadata": {
    "id": "a25f3325-61a1-4d40-9672-f853c6f0d092"
   },
   "outputs": [],
   "source": [
    "def fit_and_save_best_model_vit(model_name, model, epochs=EPOCHS):\n",
    "    ##########################################################################################################\n",
    "\n",
    "    # Criteria for early stopping\n",
    "    EarlyStop_callback = EarlyStopping(min_delta=0.0001, patience=PATIENCE_EARLY_STOP, restore_best_weights=True)\n",
    "    ##########################################################################################################\n",
    "\n",
    "    saved_best_weights = 'best_'+model_name+'_weights'\n",
    "    PATH_BEST_WEIGHT_SAVE = os.path.join(PATH_BEST_SAVE_WEIGHT, saved_best_weights)\n",
    "    # Set up a model checkpoint to save the best model during training\n",
    "    best_weight_callback= ModelCheckpoint(filepath=PATH_BEST_WEIGHT_SAVE,\n",
    "                                          monitor=SCORE_TO_MONITOR,\n",
    "                                          save_best_only=True,\n",
    "                                          mode=SCORE_OBJECTIVE,\n",
    "                                          verbose=1,\n",
    "                                          save_weights_only=True )\n",
    "\n",
    "    ##########################################################################################################\n",
    "    # # Setup the ReduceLROnPlateau callback\n",
    "    reduce_LR = ReduceLROnPlateau(\n",
    "        factor=REDUCTION_FACTOR,      # Factor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "        patience=PATIENCE_LR_REDUCE,      # Number of epochs with no improvement after which learning rate will be reduced.\n",
    "        verbose=1,       # int. 0: quiet, 1: update messages.\n",
    "        min_lr=MIN_LR,   # Lower bound on the learning rate.\n",
    "        cooldown = COOLDOWN_EPOCHS\n",
    "    )\n",
    "\n",
    "    my_callbacks = [best_weight_callback , reduce_LR , EarlyStop_callback]\n",
    "    ##########################################################################################################\n",
    "    start_time = time.time()\n",
    "    # Fitting the model\n",
    "    train_history = model.fit(\n",
    "        train_generator,\n",
    "        epochs= epochs,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=valid_generator,\n",
    "        callbacks=my_callbacks,\n",
    "    )\n",
    "    total_time = time.time() -start_time\n",
    "    return  PATH_BEST_WEIGHT_SAVE, train_history , total_time, model#model_saving_path,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f7a2c-c72e-46d6-bdf6-ea7c300419c9",
   "metadata": {
    "id": "938f7a2c-c72e-46d6-bdf6-ea7c300419c9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Essential functions (saving result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86f6126",
   "metadata": {
    "id": "b86f6126",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_history(training_history_object, list_of_metrics=None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        training_history_object:: Object returned by model.fit() function in keras\n",
    "        list_of_metrics        :: A list of metrics to be plotted. Use if you only\n",
    "                                  want to plot a subset of the total set of metrics\n",
    "                                  in the training history object. By Default it will\n",
    "                                  plot all of them in individual subplots.\n",
    "    \"\"\"\n",
    "    history_dict = training_history_object.history\n",
    "\n",
    "    ###################ADDDED NEW################################################\n",
    "    # Remove 'lr' and 'val_lr' keys from history_dict if they exist\n",
    "    history_dict.pop('lr', None)\n",
    "    history_dict.pop('val_lr', None)\n",
    "    #############################################################################\n",
    "\n",
    "    if list_of_metrics is None:\n",
    "        list_of_metrics = [key for key in list(history_dict.keys()) if 'val_' not in key]\n",
    "    trainHistDF = pd.DataFrame(history_dict)\n",
    "    # trainHistDF.head()\n",
    "    train_keys = list_of_metrics\n",
    "    valid_keys = ['val_' + key for key in train_keys]\n",
    "    nr_plots = len(train_keys)\n",
    "    fig, ax = plt.subplots(1,nr_plots,figsize=(5*nr_plots,4))\n",
    "    for i in range(len(train_keys)):\n",
    "        ax[i].plot(np.array(trainHistDF[train_keys[i]]), label='Training')\n",
    "        ax[i].plot(np.array(trainHistDF[valid_keys[i]]), label='Validation')\n",
    "        ax[i].set_xlabel('Epoch')\n",
    "        ax[i].set_title(train_keys[i])\n",
    "        ax[i].grid('on')\n",
    "        ax[i].legend()\n",
    "    fig.tight_layout\n",
    "    # plt.show()\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        # Save the plot to a PDF\n",
    "        pdf_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_training_history.pdf\")\n",
    "        with PdfPages(pdf_filename) as pdf:\n",
    "            pdf.savefig(fig)\n",
    "            if SHOW_RESULTS:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0848ff76-13fd-491e-bdda-546f69c4bd62",
   "metadata": {
    "id": "0848ff76-13fd-491e-bdda-546f69c4bd62"
   },
   "outputs": [],
   "source": [
    "def show_save_confusion_matrix(predicted_labels, target_labels):\n",
    "    cm = confusion_matrix(target_labels, predicted_labels)\n",
    "\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='g',  cmap='Greens')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    # plt.show()\n",
    "\n",
    "    # Save the plot to a PDF\n",
    "    if SAVE_RESULTS:\n",
    "        pdf_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_confusion_matrix.pdf\")\n",
    "        with PdfPages(pdf_filename) as pdf:\n",
    "            pdf.savefig()  # saves the current figure into a pdf page\n",
    "            # plt.close()\n",
    "            if SHOW_RESULTS:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94d4d2fe-fff3-404e-9b5d-dcb57f615d7c",
   "metadata": {
    "id": "94d4d2fe-fff3-404e-9b5d-dcb57f615d7c"
   },
   "outputs": [],
   "source": [
    "def calculate_TF_TP_FP_FN(true_labels_y_test, predicted_labels):\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(true_labels_y_test, predicted_labels)\n",
    "\n",
    "    class_to_performance_data = {}\n",
    "    # Calculate TP, FP, TN, FN for each class\n",
    "    num_classes = cm.shape[0]\n",
    "    for cls in range(num_classes):\n",
    "        TP = cm[cls, cls]\n",
    "        FP = cm[:, cls].sum() - TP\n",
    "        FN = cm[cls, :].sum() - TP\n",
    "        TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "        # Calculate support for each class\n",
    "        support = TP + FN\n",
    "\n",
    "        class_to_performance_data[cls] = {'TP': TP, 'FP': FP, 'TN': TN, 'FN': FN, 'Support': support}\n",
    "    return class_to_performance_data\n",
    "\n",
    "\n",
    "def calculate_metrics(class_to_performance_data, accuracy, SHOW_RESULTS=True, SAVE_RESULTS=True):\n",
    "    metrics_summary = {\n",
    "        'overall':{},\n",
    "        'Macro': {},\n",
    "        'Weighted': {}\n",
    "    }\n",
    "\n",
    "    metrics_summary[ 'overall']= {'accuracy': accuracy}\n",
    "\n",
    "    # Lists to store metric values for macro averaging\n",
    "    precision_list, recall_list, f1_score_list = [], [], []\n",
    "    fpr_list, fnr_list, fdr_list, npv_list = [], [], [], []\n",
    "\n",
    "    # Variables for weighted sum of metrics\n",
    "    weighted_precision, weighted_recall, weighted_f1 = 0, 0, 0\n",
    "    weighted_fpr, weighted_fnr, weighted_fdr, weighted_npv = 0, 0, 0, 0\n",
    "    total_support = 0\n",
    "\n",
    "    # Calculate metrics for each class\n",
    "    for class_id, metrics in class_to_performance_data.items():\n",
    "        tp = metrics['TP']\n",
    "        fp = metrics['FP']\n",
    "        tn = metrics['TN']\n",
    "        fn = metrics['FN']\n",
    "        support = metrics['Support']\n",
    "\n",
    "        # Basic evaluation metrics\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        # Additional evaluation metrics\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        fnr = fn / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        fdr = fp / (fp + tp) if (fp + tp) > 0 else 0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "        # Append to lists for macro averaging\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1_score)\n",
    "        fpr_list.append(fpr)\n",
    "        fnr_list.append(fnr)\n",
    "        fdr_list.append(fdr)\n",
    "        npv_list.append(npv)\n",
    "\n",
    "        # Weighted sum of metrics\n",
    "        weighted_precision += precision * support\n",
    "        weighted_recall += recall * support\n",
    "        weighted_f1 += f1_score * support\n",
    "        weighted_fpr += fpr * support\n",
    "        weighted_fnr += fnr * support\n",
    "        weighted_fdr += fdr * support\n",
    "        weighted_npv += npv * support\n",
    "        total_support += support\n",
    "\n",
    "    # Calculate macro averages and round to 5 decimal places\n",
    "    metrics_summary['Macro']['Precision'] = round(sum(precision_list) / len(precision_list), 5)\n",
    "    metrics_summary['Macro']['Recall'] = round(sum(recall_list) / len(recall_list), 5)\n",
    "    metrics_summary['Macro']['F1-Score'] = round(sum(f1_score_list) / len(f1_score_list), 5)\n",
    "    metrics_summary['Macro']['FPR'] = round(sum(fpr_list) / len(fpr_list), 5)\n",
    "    metrics_summary['Macro']['FNR'] = round(sum(fnr_list) / len(fnr_list), 5)\n",
    "    metrics_summary['Macro']['FDR'] = round(sum(fdr_list) / len(fdr_list), 5)\n",
    "    metrics_summary['Macro']['NPV'] = round(sum(npv_list) / len(npv_list), 5)\n",
    "\n",
    "    # Calculate weighted averages and round to 5 decimal places\n",
    "    if total_support > 0:\n",
    "        metrics_summary['Weighted']['Precision'] = round(weighted_precision / total_support, 5)\n",
    "        metrics_summary['Weighted']['Recall'] = round(weighted_recall / total_support, 5)\n",
    "        metrics_summary['Weighted']['F1-Score'] = round(weighted_f1 / total_support, 5)\n",
    "        metrics_summary['Weighted']['FPR'] = round(weighted_fpr / total_support, 5)\n",
    "        metrics_summary['Weighted']['FNR'] = round(weighted_fnr / total_support, 5)\n",
    "        metrics_summary['Weighted']['FDR'] = round(weighted_fdr / total_support, 5)\n",
    "        metrics_summary['Weighted']['NPV'] = round(weighted_npv / total_support, 5)\n",
    "\n",
    "    # Convert the nested dictionary into a DataFrame\n",
    "    report_df = pd.DataFrame.from_dict({(i+\" \"+j): metrics_summary[i][j]  for i in metrics_summary.keys()  for j in metrics_summary[i].keys()}, orient='index').reset_index()\n",
    "    # Rename columns for clarity\n",
    "    report_df.columns = ['Metric Type', 'Value']\n",
    "    if SHOW_RESULTS:\n",
    "        display(report_df)\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        # if not os.path.exists(PATH_TO_SAVE_RESULT):\n",
    "        # # If it does not exist, create it\n",
    "        #     os.makedirs(PATH_TO_SAVE_RESULT)\n",
    "\n",
    "        prediction_report_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_all_performance_report.csv\" )\n",
    "        # Save the DataFrame to a CSV file\n",
    "        report_df.to_csv(prediction_report_filename, index=True)\n",
    "\n",
    "    # return metrics_summary\n",
    "\n",
    "def calculate_accuracy(true_labels_y_test, predicted_labels):\n",
    "    # Ensure the inputs are NumPy arrays for element-wise comparison\n",
    "    true_labels_y_test = np.array(true_labels_y_test)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "    # Calculate the number of correct predictions\n",
    "    correct_predictions = np.sum(true_labels_y_test == predicted_labels)\n",
    "\n",
    "    # Calculate the total number of predictions\n",
    "    total_predictions = len(true_labels_y_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "\n",
    "    # Round accuracy to 5 decimal places\n",
    "    accuracy = round(accuracy, 5)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11b63a55-74b4-4982-9feb-e6776d23f685",
   "metadata": {
    "id": "11b63a55-74b4-4982-9feb-e6776d23f685"
   },
   "outputs": [],
   "source": [
    "def store_classification_report(predicted_labels, target_labels):\n",
    "    report_dict = classification_report(target_labels, predicted_labels, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    if SHOW_RESULTS:\n",
    "        display(report_df)\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        prediction_report_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_classification_report.csv\" )\n",
    "        # Save the DataFrame to a CSV file\n",
    "        report_df.to_csv(prediction_report_filename, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56b36c2e-1a4a-4895-ba57-fa7fe0e6caa5",
   "metadata": {
    "id": "56b36c2e-1a4a-4895-ba57-fa7fe0e6caa5"
   },
   "outputs": [],
   "source": [
    "def show_save_test_results(test_generator, best_model):\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy, test_f1_score = best_model.evaluate(test_generator)\n",
    "\n",
    "    # print(f\"Test Loss: {test_loss}\")\n",
    "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
    "    # print(f\"Test F1 Score: {test_f1_score}\")\n",
    "\n",
    "    test_results = {\n",
    "        'model_name': model_name,\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_f1_score': test_f1_score\n",
    "    }\n",
    "\n",
    "        # Convert the dictionary to a DataFrame\n",
    "    report_df = pd.DataFrame([test_results])\n",
    "\n",
    "    if SHOW_RESULTS:\n",
    "        display(report_df)\n",
    "\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        path_to_save = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_model_performance.csv\")\n",
    "        # Save the DataFrame to a CSV file\n",
    "        report_df.to_csv(path_to_save , index=False)\n",
    "        del report_df, test_results\n",
    "    return  test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2181fbed-1eed-4090-81b7-32e7b309aebf",
   "metadata": {
    "id": "2181fbed-1eed-4090-81b7-32e7b309aebf"
   },
   "outputs": [],
   "source": [
    "def calculate_test_performance_metrics_all(predicted_labels, target_labels, test_loss):\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(target_labels, predicted_labels)\n",
    "    precision_macro = precision_score(target_labels, predicted_labels, average='macro')\n",
    "    recall_macro = recall_score(target_labels, predicted_labels, average='macro')\n",
    "    f1_macro = f1_score_report(target_labels, predicted_labels, average='macro')\n",
    "\n",
    "    precision_weighted = precision_score(target_labels, predicted_labels, average='weighted')\n",
    "    recall_weighted = recall_score(target_labels, predicted_labels, average='weighted')\n",
    "    f1_weighted = f1_score_report(target_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    # Create a dictionary to hold the metrics\n",
    "    test_results = {\n",
    "        'Model Name': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Macro Precision': precision_macro,\n",
    "        'Macro Recall': recall_macro,\n",
    "        'Macro F1-Score': f1_macro,\n",
    "        'Weighted Precision': precision_weighted,\n",
    "        'Weighted Recall': recall_weighted,\n",
    "        'Weighted F1-Score': f1_weighted,\n",
    "        'Loss': test_loss\n",
    "    }\n",
    "\n",
    "        # Convert the dictionary to a DataFrame\n",
    "    report_df = pd.DataFrame([test_results])\n",
    "\n",
    "    if SHOW_RESULTS:\n",
    "        display(report_df)\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        path_to_save = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_model_all_test_performance.csv\")\n",
    "        # Save the DataFrame to a CSV file\n",
    "        report_df.to_csv(path_to_save , index=False)\n",
    "\n",
    "    del report_df, test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3608cfb",
   "metadata": {
    "id": "f3608cfb"
   },
   "source": [
    "# MODEL CREATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f2e3a1d-7cea-4cad-ac91-4bea7e8f7427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit import ViT\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "def get_original_vit():\n",
    "    model = ViT( # v1 val_accuracy: 0.3172 - val_f1_score: 0.1981\n",
    "    image_size = 128,\n",
    "    patch_size = 16,\n",
    "    num_classes = NUM_CLASSES,\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 1024,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    "    )\n",
    "\n",
    "    optimizer = Adam(learning_rate=INITIAL_LR)\n",
    "    model.compile(loss=CategoricalCrossentropy(from_logits=True),\n",
    "                  run_eagerly=True,\n",
    "                  metrics=['accuracy', f1_score],\n",
    "                  optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6308b58-680e-434c-ae75-07ea53e2cad2",
   "metadata": {
    "id": "f6308b58-680e-434c-ae75-07ea53e2cad2"
   },
   "source": [
    "# Train and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06642652-4393-4874-b0eb-e5fed0234b00",
   "metadata": {
    "id": "06642652-4393-4874-b0eb-e5fed0234b00"
   },
   "outputs": [],
   "source": [
    "# if model_name=='DenseNet121':\n",
    "#     model= get_DenseNet121()\n",
    "# elif model_name=='MobileNet':\n",
    "#     model= get_MobileNet_original()\n",
    "# elif model_name=='Xception':\n",
    "#     model= get_Xception()\n",
    "# elif model_name=='InceptionV3':\n",
    "#     model= get_InceptionV3()\n",
    "\n",
    "# ##Getting the model\n",
    "# model= get_MobileNet_original()\n",
    "# model= get_DenseNet121()\n",
    "# model= get_Xception()\n",
    "# model= get_InceptionV3()\n",
    "# model = get_cait()\n",
    "# # ## Getting the model\n",
    "# model = get_basic_CNN()\n",
    "# model = get_ensemble2_model()\n",
    "model = get_original_vit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65eeabc6-ab0f-4054-ae45-9a8e2d7d2294",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2715398,
     "status": "ok",
     "timestamp": 1710549356974,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "65eeabc6-ab0f-4054-ae45-9a8e2d7d2294",
    "outputId": "c7b0f53c-869f-4016-ab8a-4a053f4a466a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 1.7582 - accuracy: 0.3054 - f1_score: 0.3018\n",
      "Epoch 1: val_f1_score improved from -inf to 0.34216, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 113s 2s/step - loss: 1.7582 - accuracy: 0.3054 - f1_score: 0.3018 - val_loss: 1.2606 - val_accuracy: 0.4229 - val_f1_score: 0.3422 - lr: 1.0000e-04\n",
      "Epoch 2/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 1.2043 - accuracy: 0.4540 - f1_score: 0.4502\n",
      "Epoch 2: val_f1_score improved from 0.34216 to 0.48041, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 113s 2s/step - loss: 1.2043 - accuracy: 0.4540 - f1_score: 0.4502 - val_loss: 1.2033 - val_accuracy: 0.5081 - val_f1_score: 0.4804 - lr: 1.0000e-04\n",
      "Epoch 3/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 1.0204 - accuracy: 0.5975 - f1_score: 0.5937\n",
      "Epoch 3: val_f1_score improved from 0.48041 to 0.67019, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 117s 2s/step - loss: 1.0204 - accuracy: 0.5975 - f1_score: 0.5937 - val_loss: 0.8873 - val_accuracy: 0.6749 - val_f1_score: 0.6702 - lr: 1.0000e-04\n",
      "Epoch 4/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.8598 - accuracy: 0.6634 - f1_score: 0.6622\n",
      "Epoch 4: val_f1_score improved from 0.67019 to 0.70750, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 121s 2s/step - loss: 0.8598 - accuracy: 0.6634 - f1_score: 0.6622 - val_loss: 0.8116 - val_accuracy: 0.7080 - val_f1_score: 0.7075 - lr: 1.0000e-04\n",
      "Epoch 5/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.8168 - accuracy: 0.6814 - f1_score: 0.6816\n",
      "Epoch 5: val_f1_score did not improve from 0.70750\n",
      "52/52 [==============================] - 117s 2s/step - loss: 0.8168 - accuracy: 0.6814 - f1_score: 0.6816 - val_loss: 0.7844 - val_accuracy: 0.7030 - val_f1_score: 0.7058 - lr: 1.0000e-04\n",
      "Epoch 6/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.7808 - accuracy: 0.6907 - f1_score: 0.6912\n",
      "Epoch 6: val_f1_score did not improve from 0.70750\n",
      "52/52 [==============================] - 121s 2s/step - loss: 0.7808 - accuracy: 0.6907 - f1_score: 0.6912 - val_loss: 0.8815 - val_accuracy: 0.6763 - val_f1_score: 0.6719 - lr: 1.0000e-04\n",
      "Epoch 7/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.7337 - accuracy: 0.7067 - f1_score: 0.7070\n",
      "Epoch 7: val_f1_score improved from 0.70750 to 0.72493, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 117s 2s/step - loss: 0.7337 - accuracy: 0.7067 - f1_score: 0.7070 - val_loss: 0.6965 - val_accuracy: 0.7255 - val_f1_score: 0.7249 - lr: 1.0000e-04\n",
      "Epoch 8/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6501 - accuracy: 0.7443 - f1_score: 0.7452\n",
      "Epoch 8: val_f1_score did not improve from 0.72493\n",
      "52/52 [==============================] - 121s 2s/step - loss: 0.6501 - accuracy: 0.7443 - f1_score: 0.7452 - val_loss: 0.6840 - val_accuracy: 0.7213 - val_f1_score: 0.7139 - lr: 1.0000e-04\n",
      "Epoch 9/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5953 - accuracy: 0.7596 - f1_score: 0.7601\n",
      "Epoch 9: val_f1_score improved from 0.72493 to 0.76221, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 123s 2s/step - loss: 0.5953 - accuracy: 0.7596 - f1_score: 0.7601 - val_loss: 0.6110 - val_accuracy: 0.7664 - val_f1_score: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 10/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.7828 - f1_score: 0.7838\n",
      "Epoch 10: val_f1_score improved from 0.76221 to 0.77820, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 123s 2s/step - loss: 0.5600 - accuracy: 0.7828 - f1_score: 0.7838 - val_loss: 0.5630 - val_accuracy: 0.7790 - val_f1_score: 0.7782 - lr: 1.0000e-04\n",
      "Epoch 11/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.7825 - f1_score: 0.7838\n",
      "Epoch 11: val_f1_score did not improve from 0.77820\n",
      "52/52 [==============================] - 124s 2s/step - loss: 0.5424 - accuracy: 0.7825 - f1_score: 0.7838 - val_loss: 0.5444 - val_accuracy: 0.7720 - val_f1_score: 0.7719 - lr: 1.0000e-04\n",
      "Epoch 12/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.8066 - f1_score: 0.8074\n",
      "Epoch 12: val_f1_score improved from 0.77820 to 0.82824, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 121s 2s/step - loss: 0.4889 - accuracy: 0.8066 - f1_score: 0.8074 - val_loss: 0.4442 - val_accuracy: 0.8297 - val_f1_score: 0.8282 - lr: 1.0000e-04\n",
      "Epoch 13/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.8048 - f1_score: 0.8054\n",
      "Epoch 13: val_f1_score did not improve from 0.82824\n",
      "52/52 [==============================] - 124s 2s/step - loss: 0.4974 - accuracy: 0.8048 - f1_score: 0.8054 - val_loss: 0.5293 - val_accuracy: 0.7987 - val_f1_score: 0.7987 - lr: 1.0000e-04\n",
      "Epoch 14/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8222 - f1_score: 0.8231\n",
      "Epoch 14: val_f1_score improved from 0.82824 to 0.85577, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 128s 2s/step - loss: 0.4546 - accuracy: 0.8222 - f1_score: 0.8231 - val_loss: 0.3781 - val_accuracy: 0.8557 - val_f1_score: 0.8558 - lr: 1.0000e-04\n",
      "Epoch 15/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.8261 - f1_score: 0.8278\n",
      "Epoch 15: val_f1_score did not improve from 0.85577\n",
      "52/52 [==============================] - 130s 2s/step - loss: 0.4357 - accuracy: 0.8261 - f1_score: 0.8278 - val_loss: 0.3905 - val_accuracy: 0.8445 - val_f1_score: 0.8471 - lr: 1.0000e-04\n",
      "Epoch 16/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8493 - f1_score: 0.8501\n",
      "Epoch 16: val_f1_score improved from 0.85577 to 0.86271, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 132s 3s/step - loss: 0.4030 - accuracy: 0.8493 - f1_score: 0.8501 - val_loss: 0.3832 - val_accuracy: 0.8621 - val_f1_score: 0.8627 - lr: 1.0000e-04\n",
      "Epoch 17/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.8610 - f1_score: 0.8617\n",
      "Epoch 17: val_f1_score improved from 0.86271 to 0.88145, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 135s 3s/step - loss: 0.3566 - accuracy: 0.8610 - f1_score: 0.8617 - val_loss: 0.3410 - val_accuracy: 0.8818 - val_f1_score: 0.8814 - lr: 1.0000e-04\n",
      "Epoch 18/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3615 - accuracy: 0.8670 - f1_score: 0.8683\n",
      "Epoch 18: val_f1_score did not improve from 0.88145\n",
      "52/52 [==============================] - 132s 3s/step - loss: 0.3615 - accuracy: 0.8670 - f1_score: 0.8683 - val_loss: 0.3857 - val_accuracy: 0.8473 - val_f1_score: 0.8486 - lr: 1.0000e-04\n",
      "Epoch 19/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.8764 - f1_score: 0.8770\n",
      "Epoch 19: val_f1_score did not improve from 0.88145\n",
      "52/52 [==============================] - 136s 3s/step - loss: 0.3276 - accuracy: 0.8764 - f1_score: 0.8770 - val_loss: 0.3748 - val_accuracy: 0.8698 - val_f1_score: 0.8705 - lr: 1.0000e-04\n",
      "Epoch 20/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.8950 - f1_score: 0.8963\n",
      "Epoch 20: val_f1_score did not improve from 0.88145\n",
      "52/52 [==============================] - 140s 3s/step - loss: 0.2948 - accuracy: 0.8950 - f1_score: 0.8963 - val_loss: 0.3237 - val_accuracy: 0.8712 - val_f1_score: 0.8715 - lr: 1.0000e-04\n",
      "Epoch 21/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.8761 - f1_score: 0.8772\n",
      "Epoch 21: val_f1_score did not improve from 0.88145\n",
      "52/52 [==============================] - 143s 3s/step - loss: 0.3092 - accuracy: 0.8761 - f1_score: 0.8772 - val_loss: 0.2957 - val_accuracy: 0.8740 - val_f1_score: 0.8733 - lr: 1.0000e-04\n",
      "Epoch 22/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.9016 - f1_score: 0.9023\n",
      "Epoch 22: val_f1_score improved from 0.88145 to 0.90963, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 151s 3s/step - loss: 0.2706 - accuracy: 0.9016 - f1_score: 0.9023 - val_loss: 0.2434 - val_accuracy: 0.9106 - val_f1_score: 0.9096 - lr: 1.0000e-04\n",
      "Epoch 23/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8854 - f1_score: 0.8862\n",
      "Epoch 23: val_f1_score did not improve from 0.90963\n",
      "52/52 [==============================] - 150s 3s/step - loss: 0.3060 - accuracy: 0.8854 - f1_score: 0.8862 - val_loss: 0.2913 - val_accuracy: 0.9085 - val_f1_score: 0.9096 - lr: 1.0000e-04\n",
      "Epoch 24/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2396 - accuracy: 0.9058 - f1_score: 0.9069\n",
      "Epoch 24: val_f1_score improved from 0.90963 to 0.92364, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 155s 3s/step - loss: 0.2396 - accuracy: 0.9058 - f1_score: 0.9069 - val_loss: 0.1853 - val_accuracy: 0.9226 - val_f1_score: 0.9236 - lr: 1.0000e-04\n",
      "Epoch 25/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9248 - f1_score: 0.9256\n",
      "Epoch 25: val_f1_score improved from 0.92364 to 0.93142, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 158s 3s/step - loss: 0.2049 - accuracy: 0.9248 - f1_score: 0.9256 - val_loss: 0.1828 - val_accuracy: 0.9310 - val_f1_score: 0.9314 - lr: 1.0000e-04\n",
      "Epoch 26/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9359 - f1_score: 0.9367\n",
      "Epoch 26: val_f1_score improved from 0.93142 to 0.95020, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 167s 3s/step - loss: 0.1689 - accuracy: 0.9359 - f1_score: 0.9367 - val_loss: 0.1311 - val_accuracy: 0.9493 - val_f1_score: 0.9502 - lr: 1.0000e-04\n",
      "Epoch 27/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9281 - f1_score: 0.9291\n",
      "Epoch 27: val_f1_score did not improve from 0.95020\n",
      "52/52 [==============================] - 183s 4s/step - loss: 0.1885 - accuracy: 0.9281 - f1_score: 0.9291 - val_loss: 0.2043 - val_accuracy: 0.9134 - val_f1_score: 0.9143 - lr: 1.0000e-04\n",
      "Epoch 28/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1851 - accuracy: 0.9299 - f1_score: 0.9307\n",
      "Epoch 28: val_f1_score did not improve from 0.95020\n",
      "52/52 [==============================] - 189s 4s/step - loss: 0.1851 - accuracy: 0.9299 - f1_score: 0.9307 - val_loss: 0.1508 - val_accuracy: 0.9409 - val_f1_score: 0.9417 - lr: 1.0000e-04\n",
      "Epoch 29/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.9380 - f1_score: 0.9388\n",
      "Epoch 29: val_f1_score improved from 0.95020 to 0.95553, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 202s 4s/step - loss: 0.1658 - accuracy: 0.9380 - f1_score: 0.9388 - val_loss: 0.1132 - val_accuracy: 0.9550 - val_f1_score: 0.9555 - lr: 1.0000e-04\n",
      "Epoch 30/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 0.9477 - f1_score: 0.9484\n",
      "Epoch 30: val_f1_score did not improve from 0.95553\n",
      "52/52 [==============================] - 203s 4s/step - loss: 0.1428 - accuracy: 0.9477 - f1_score: 0.9484 - val_loss: 0.1641 - val_accuracy: 0.9381 - val_f1_score: 0.9397 - lr: 1.0000e-04\n",
      "Epoch 31/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9392 - f1_score: 0.9401\n",
      "Epoch 31: val_f1_score did not improve from 0.95553\n",
      "52/52 [==============================] - 217s 4s/step - loss: 0.1621 - accuracy: 0.9392 - f1_score: 0.9401 - val_loss: 0.1577 - val_accuracy: 0.9451 - val_f1_score: 0.9458 - lr: 1.0000e-04\n",
      "Epoch 32/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9564 - f1_score: 0.9569\n",
      "Epoch 32: val_f1_score improved from 0.95553 to 0.96151, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "52/52 [==============================] - 233s 4s/step - loss: 0.1166 - accuracy: 0.9564 - f1_score: 0.9569 - val_loss: 0.1202 - val_accuracy: 0.9606 - val_f1_score: 0.9615 - lr: 1.0000e-04\n",
      "Epoch 33/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9771 - f1_score: 0.9775\n",
      "Epoch 33: val_f1_score improved from 0.96151 to 0.98201, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 241s 5s/step - loss: 0.0678 - accuracy: 0.9771 - f1_score: 0.9775 - val_loss: 0.0414 - val_accuracy: 0.9817 - val_f1_score: 0.9820 - lr: 5.0000e-05\n",
      "Epoch 34/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9795 - f1_score: 0.9798\n",
      "Epoch 34: val_f1_score did not improve from 0.98201\n",
      "52/52 [==============================] - 249s 5s/step - loss: 0.0633 - accuracy: 0.9795 - f1_score: 0.9798 - val_loss: 0.0521 - val_accuracy: 0.9796 - val_f1_score: 0.9796 - lr: 5.0000e-05\n",
      "Epoch 35/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9777 - f1_score: 0.9781\n",
      "Epoch 35: val_f1_score improved from 0.98201 to 0.98266, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 263s 5s/step - loss: 0.0594 - accuracy: 0.9777 - f1_score: 0.9781 - val_loss: 0.0477 - val_accuracy: 0.9824 - val_f1_score: 0.9827 - lr: 5.0000e-05\n",
      "Epoch 36/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9777 - f1_score: 0.9781\n",
      "Epoch 36: val_f1_score improved from 0.98266 to 0.98592, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "52/52 [==============================] - 271s 5s/step - loss: 0.0591 - accuracy: 0.9777 - f1_score: 0.9781 - val_loss: 0.0474 - val_accuracy: 0.9859 - val_f1_score: 0.9859 - lr: 5.0000e-05\n",
      "Epoch 37/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9859 - f1_score: 0.9862\n",
      "Epoch 37: val_f1_score improved from 0.98592 to 0.98895, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 277s 5s/step - loss: 0.0434 - accuracy: 0.9859 - f1_score: 0.9862 - val_loss: 0.0308 - val_accuracy: 0.9887 - val_f1_score: 0.9890 - lr: 2.5000e-05\n",
      "Epoch 38/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9874 - f1_score: 0.9875\n",
      "Epoch 38: val_f1_score improved from 0.98895 to 0.99436, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 291s 6s/step - loss: 0.0393 - accuracy: 0.9874 - f1_score: 0.9875 - val_loss: 0.0216 - val_accuracy: 0.9944 - val_f1_score: 0.9944 - lr: 2.5000e-05\n",
      "Epoch 39/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9853 - f1_score: 0.9856\n",
      "Epoch 39: val_f1_score did not improve from 0.99436\n",
      "52/52 [==============================] - 295s 6s/step - loss: 0.0431 - accuracy: 0.9853 - f1_score: 0.9856 - val_loss: 0.0332 - val_accuracy: 0.9887 - val_f1_score: 0.9890 - lr: 2.5000e-05\n",
      "Epoch 40/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9874 - f1_score: 0.9875\n",
      "Epoch 40: val_f1_score did not improve from 0.99436\n",
      "52/52 [==============================] - 310s 6s/step - loss: 0.0396 - accuracy: 0.9874 - f1_score: 0.9875 - val_loss: 0.0297 - val_accuracy: 0.9887 - val_f1_score: 0.9889 - lr: 2.5000e-05\n",
      "Epoch 41/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9844 - f1_score: 0.9846\n",
      "Epoch 41: val_f1_score did not improve from 0.99436\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "52/52 [==============================] - 324s 6s/step - loss: 0.0444 - accuracy: 0.9844 - f1_score: 0.9846 - val_loss: 0.0250 - val_accuracy: 0.9923 - val_f1_score: 0.9923 - lr: 2.5000e-05\n",
      "Epoch 42/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9892 - f1_score: 0.9893\n",
      "Epoch 42: val_f1_score did not improve from 0.99436\n",
      "52/52 [==============================] - 328s 6s/step - loss: 0.0330 - accuracy: 0.9892 - f1_score: 0.9893 - val_loss: 0.0291 - val_accuracy: 0.9916 - val_f1_score: 0.9918 - lr: 1.2500e-05\n",
      "Epoch 43/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9934 - f1_score: 0.9934\n",
      "Epoch 43: val_f1_score improved from 0.99436 to 0.99497, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 344s 7s/step - loss: 0.0225 - accuracy: 0.9934 - f1_score: 0.9934 - val_loss: 0.0206 - val_accuracy: 0.9951 - val_f1_score: 0.9950 - lr: 1.2500e-05\n",
      "Epoch 44/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9922 - f1_score: 0.9923\n",
      "Epoch 44: val_f1_score did not improve from 0.99497\n",
      "52/52 [==============================] - 352s 7s/step - loss: 0.0249 - accuracy: 0.9922 - f1_score: 0.9923 - val_loss: 0.0320 - val_accuracy: 0.9901 - val_f1_score: 0.9902 - lr: 1.2500e-05\n",
      "Epoch 45/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9934 - f1_score: 0.9935\n",
      "Epoch 45: val_f1_score did not improve from 0.99497\n",
      "52/52 [==============================] - 367s 7s/step - loss: 0.0223 - accuracy: 0.9934 - f1_score: 0.9935 - val_loss: 0.0166 - val_accuracy: 0.9944 - val_f1_score: 0.9944 - lr: 1.2500e-05\n",
      "Epoch 46/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9931 - f1_score: 0.9932\n",
      "Epoch 46: val_f1_score did not improve from 0.99497\n",
      "52/52 [==============================] - 383s 7s/step - loss: 0.0242 - accuracy: 0.9931 - f1_score: 0.9932 - val_loss: 0.0242 - val_accuracy: 0.9923 - val_f1_score: 0.9924 - lr: 1.2500e-05\n",
      "Epoch 47/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9916 - f1_score: 0.9917\n",
      "Epoch 47: val_f1_score did not improve from 0.99497\n",
      "52/52 [==============================] - 393s 8s/step - loss: 0.0258 - accuracy: 0.9916 - f1_score: 0.9917 - val_loss: 0.0194 - val_accuracy: 0.9944 - val_f1_score: 0.9944 - lr: 1.2500e-05\n",
      "Epoch 48/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9910 - f1_score: 0.9912\n",
      "Epoch 48: val_f1_score did not improve from 0.99497\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "52/52 [==============================] - 403s 8s/step - loss: 0.0273 - accuracy: 0.9910 - f1_score: 0.9912 - val_loss: 0.0181 - val_accuracy: 0.9937 - val_f1_score: 0.9938 - lr: 1.2500e-05\n",
      "Epoch 49/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9904 - f1_score: 0.9904\n",
      "Epoch 49: val_f1_score did not improve from 0.99497\n",
      "52/52 [==============================] - 416s 8s/step - loss: 0.0274 - accuracy: 0.9904 - f1_score: 0.9904 - val_loss: 0.0244 - val_accuracy: 0.9930 - val_f1_score: 0.9930 - lr: 6.2500e-06\n",
      "Epoch 50/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9910 - f1_score: 0.9911\n",
      "Epoch 50: val_f1_score improved from 0.99497 to 0.99657, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 434s 8s/step - loss: 0.0277 - accuracy: 0.9910 - f1_score: 0.9911 - val_loss: 0.0150 - val_accuracy: 0.9965 - val_f1_score: 0.9966 - lr: 6.2500e-06\n",
      "Epoch 51/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9928 - f1_score: 0.9929\n",
      "Epoch 51: val_f1_score did not improve from 0.99657\n",
      "52/52 [==============================] - 441s 8s/step - loss: 0.0217 - accuracy: 0.9928 - f1_score: 0.9929 - val_loss: 0.0190 - val_accuracy: 0.9930 - val_f1_score: 0.9930 - lr: 6.2500e-06\n",
      "Epoch 52/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9892 - f1_score: 0.9893\n",
      "Epoch 52: val_f1_score improved from 0.99657 to 0.99718, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 457s 9s/step - loss: 0.0292 - accuracy: 0.9892 - f1_score: 0.9893 - val_loss: 0.0125 - val_accuracy: 0.9972 - val_f1_score: 0.9972 - lr: 6.2500e-06\n",
      "Epoch 53/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9937 - f1_score: 0.9938\n",
      "Epoch 53: val_f1_score did not improve from 0.99718\n",
      "52/52 [==============================] - 462s 9s/step - loss: 0.0222 - accuracy: 0.9937 - f1_score: 0.9938 - val_loss: 0.0308 - val_accuracy: 0.9901 - val_f1_score: 0.9902 - lr: 6.2500e-06\n",
      "Epoch 54/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9910 - f1_score: 0.9911\n",
      "Epoch 54: val_f1_score did not improve from 0.99718\n",
      "52/52 [==============================] - 477s 9s/step - loss: 0.0266 - accuracy: 0.9910 - f1_score: 0.9911 - val_loss: 0.0163 - val_accuracy: 0.9965 - val_f1_score: 0.9965 - lr: 6.2500e-06\n",
      "Epoch 55/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9922 - f1_score: 0.9922\n",
      "Epoch 55: val_f1_score did not improve from 0.99718\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "52/52 [==============================] - 482s 9s/step - loss: 0.0257 - accuracy: 0.9922 - f1_score: 0.9922 - val_loss: 0.0185 - val_accuracy: 0.9937 - val_f1_score: 0.9937 - lr: 6.2500e-06\n",
      "Epoch 56/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9934 - f1_score: 0.9935\n",
      "Epoch 56: val_f1_score improved from 0.99718 to 0.99785, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 499s 10s/step - loss: 0.0226 - accuracy: 0.9934 - f1_score: 0.9935 - val_loss: 0.0084 - val_accuracy: 0.9979 - val_f1_score: 0.9979 - lr: 3.1250e-06\n",
      "Epoch 57/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9940 - f1_score: 0.9940\n",
      "Epoch 57: val_f1_score did not improve from 0.99785\n",
      "52/52 [==============================] - 507s 10s/step - loss: 0.0230 - accuracy: 0.9940 - f1_score: 0.9940 - val_loss: 0.0146 - val_accuracy: 0.9944 - val_f1_score: 0.9944 - lr: 3.1250e-06\n",
      "Epoch 58/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9940 - f1_score: 0.9941\n",
      "Epoch 58: val_f1_score did not improve from 0.99785\n",
      "52/52 [==============================] - 530s 10s/step - loss: 0.0203 - accuracy: 0.9940 - f1_score: 0.9941 - val_loss: 0.0200 - val_accuracy: 0.9930 - val_f1_score: 0.9931 - lr: 3.1250e-06\n",
      "Epoch 59/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9928 - f1_score: 0.9929\n",
      "Epoch 59: val_f1_score did not improve from 0.99785\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "52/52 [==============================] - 535s 10s/step - loss: 0.0216 - accuracy: 0.9928 - f1_score: 0.9929 - val_loss: 0.0204 - val_accuracy: 0.9951 - val_f1_score: 0.9951 - lr: 3.1250e-06\n",
      "Epoch 60/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9934 - f1_score: 0.9935\n",
      "Epoch 60: val_f1_score did not improve from 0.99785\n",
      "52/52 [==============================] - 555s 11s/step - loss: 0.0195 - accuracy: 0.9934 - f1_score: 0.9935 - val_loss: 0.0094 - val_accuracy: 0.9965 - val_f1_score: 0.9965 - lr: 1.5625e-06\n",
      "Epoch 61/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9919 - f1_score: 0.9919\n",
      "Epoch 61: val_f1_score improved from 0.99785 to 0.99791, saving model to saved_outputs_all_augment\\original_vit_v2\\original_vit_v2_saved_weights\\best_original_vit_v2_weights\n",
      "52/52 [==============================] - 569s 11s/step - loss: 0.0210 - accuracy: 0.9919 - f1_score: 0.9919 - val_loss: 0.0084 - val_accuracy: 0.9979 - val_f1_score: 0.9979 - lr: 1.5625e-06\n",
      "Epoch 62/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9916 - f1_score: 0.9917\n",
      "Epoch 62: val_f1_score did not improve from 0.99791\n",
      "52/52 [==============================] - 577s 11s/step - loss: 0.0252 - accuracy: 0.9916 - f1_score: 0.9917 - val_loss: 0.0163 - val_accuracy: 0.9965 - val_f1_score: 0.9965 - lr: 1.5625e-06\n",
      "Epoch 63/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9937 - f1_score: 0.9938\n",
      "Epoch 63: val_f1_score did not improve from 0.99791\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "52/52 [==============================] - 596s 11s/step - loss: 0.0222 - accuracy: 0.9937 - f1_score: 0.9938 - val_loss: 0.0182 - val_accuracy: 0.9944 - val_f1_score: 0.9945 - lr: 1.5625e-06\n",
      "Epoch 64/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9931 - f1_score: 0.9932\n",
      "Epoch 64: val_f1_score did not improve from 0.99791\n",
      "52/52 [==============================] - 603s 12s/step - loss: 0.0213 - accuracy: 0.9931 - f1_score: 0.9932 - val_loss: 0.0087 - val_accuracy: 0.9972 - val_f1_score: 0.9973 - lr: 7.8125e-07\n",
      "Epoch 65/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9934 - f1_score: 0.9935\n",
      "Epoch 65: val_f1_score did not improve from 0.99791\n",
      "52/52 [==============================] - 621s 12s/step - loss: 0.0203 - accuracy: 0.9934 - f1_score: 0.9935 - val_loss: 0.0177 - val_accuracy: 0.9958 - val_f1_score: 0.9959 - lr: 7.8125e-07\n",
      "Epoch 66/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9943 - f1_score: 0.9944\n",
      "Epoch 66: val_f1_score did not improve from 0.99791\n",
      "52/52 [==============================] - 634s 12s/step - loss: 0.0191 - accuracy: 0.9943 - f1_score: 0.9944 - val_loss: 0.0164 - val_accuracy: 0.9951 - val_f1_score: 0.9951 - lr: 7.8125e-07\n",
      "Epoch 67/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9961 - f1_score: 0.9962\n",
      "Epoch 67: val_f1_score did not improve from 0.99791\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "52/52 [==============================] - 651s 12s/step - loss: 0.0158 - accuracy: 0.9961 - f1_score: 0.9962 - val_loss: 0.0117 - val_accuracy: 0.9958 - val_f1_score: 0.9959 - lr: 7.8125e-07\n",
      "Epoch 68/68\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9940 - f1_score: 0.9941\n",
      "Epoch 68: val_f1_score did not improve from 0.99791\n",
      "52/52 [==============================] - 667s 13s/step - loss: 0.0185 - accuracy: 0.9940 - f1_score: 0.9941 - val_loss: 0.0160 - val_accuracy: 0.9958 - val_f1_score: 0.9957 - lr: 3.9062e-07\n"
     ]
    }
   ],
   "source": [
    "# training the model and saving the best model as a check point\n",
    "PATH_BEST_WEIGHT_SAVE, train_history , total_time, best_model = fit_and_save_best_model_vit(model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a71ec9d2-c3fc-4343-ad66-42d582449842",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6502,
     "status": "ok",
     "timestamp": 1710549846747,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "a71ec9d2-c3fc-4343-ad66-42d582449842",
    "outputId": "0ce4334f-e4e9-4d0a-f2ed-49e678eb13d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 65s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from the model\n",
    "predictions = best_model.predict(test_generator, verbose=1)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_labels_y_test =  np.array(test_generator.classes) # y_test\n",
    "############################################################################################################]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "949aa4e9-386a-486d-9a7b-87ad898066a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrapped Macro AUC (100 runs):\n",
      "Mean AUC     : 0.99958\n",
      "Std Deviation: 0.00011\n",
      "95% CI       : (0.99938, 0.99978)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.999576986548474,\n",
       " 0.00011048106021130358,\n",
       " (0.9993773659701811, 0.999777856764581))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def bootstrap_auc_ci(true_labels, predicted_probs, num_classes=NUM_CLASSES, n_iterations=100, seed=SEED, save_path=None):\n",
    "    \"\"\"\n",
    "    Computes bootstrapped AUC with 95% confidence interval for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.array): Ground truth class labels (e.g., [0, 1, 2, ...])\n",
    "        predicted_probs (np.array): Predicted probabilities, shape = (n_samples, n_classes)\n",
    "        num_classes (int): Number of classes\n",
    "        n_iterations (int): Number of bootstrap iterations\n",
    "        seed (int): Random seed for reproducibility\n",
    "        save_path (str): Optional path to save AUC scores as CSV\n",
    "\n",
    "    Returns:\n",
    "        Prints mean AUC, std, and 95% CI\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    auc_scores = []\n",
    "\n",
    "    # One-hot encode true labels\n",
    "    true_labels_bin = label_binarize(true_labels, classes=np.arange(num_classes))\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        indices = np.random.choice(len(true_labels), size=len(true_labels), replace=True)\n",
    "        y_true_sample = true_labels_bin[indices]\n",
    "        y_pred_sample = predicted_probs[indices]\n",
    "\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true_sample, y_pred_sample, multi_class='ovr', average='macro')\n",
    "            auc_scores.append(auc)\n",
    "        except ValueError:\n",
    "            continue  # Skip if a class is missing in the sample\n",
    "\n",
    "    auc_scores = np.array(auc_scores)\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    std_auc = np.std(auc_scores)\n",
    "    ci_lower = np.percentile(auc_scores, 2.5)\n",
    "    ci_upper = np.percentile(auc_scores, 97.5)\n",
    "\n",
    "    print(f\"\\nBootstrapped Macro AUC ({n_iterations} runs):\")\n",
    "    print(f\"Mean AUC     : {mean_auc:.5f}\")\n",
    "    print(f\"Std Deviation: {std_auc:.5f}\")\n",
    "    print(f\"95% CI       : ({ci_lower:.5f}, {ci_upper:.5f})\")\n",
    "\n",
    "    if save_path:\n",
    "        df = pd.DataFrame({'AUC Score': auc_scores})\n",
    "        df.to_csv(save_path, index=False)\n",
    "\n",
    "    return mean_auc, std_auc, (ci_lower, ci_upper)\n",
    "\n",
    "# Call the function\n",
    "bootstrap_auc_ci(\n",
    "    true_labels=true_labels_y_test,\n",
    "    predicted_probs=predictions,\n",
    "    save_path=os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_bootstrapped_auc.csv\")\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "69dada5c-1141-4914-96bd-a8ff36749e6d",
    "da5ca5e3-a160-4ee9-a451-3041c841fad9",
    "938f7a2c-c72e-46d6-bdf6-ea7c300419c9",
    "F0UlityPEMxc",
    "3xZyTkwcDeE2",
    "esq3i0AwDhYD",
    "TU7_2IfFDkbP",
    "-PiTU6R0Dq6y",
    "usVCdrmaDvxw",
    "dfdd7a6b-3ba9-4754-af22-fa0aff5bad4e"
   ],
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-13T13:42:48.933576",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
