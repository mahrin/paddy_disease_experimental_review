{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8891c7ce",
   "metadata": {
    "id": "8891c7ce",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oXsIvnalrsWb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15674,
     "status": "ok",
     "timestamp": 1710546572485,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "oXsIvnalrsWb",
    "outputId": "0151a63a-c493-4fc2-f000-41be2efd32c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\mahri\\anaconda3\\envs\\tfgpu_env\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\mahri\\anaconda3\\envs\\tfgpu_env\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\mahri\\anaconda3\\envs\\tfgpu_env\\lib\\site-packages (from tensorflow-addons) (23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0ff7e4-cf5e-4586-a1f7-eab01ae63a15",
   "metadata": {
    "id": "8e0ff7e4-cf5e-4586-a1f7-eab01ae63a15"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os # read and manipulate local files\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score as f1_score_report\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow.keras as ks\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imgaug import augmenters as iaa # elastic_deformation\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Dense, BatchNormalization, Concatenate, GlobalAveragePooling2D\n",
    "\n",
    "# hide wornings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "################################################################################################\n",
    "# SETTING F1 SCORE\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "f1_score = F1Score(num_classes=4, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PMuxPpz9GjaY",
   "metadata": {
    "id": "PMuxPpz9GjaY"
   },
   "source": [
    "## Setting the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f806ed-e9db-4199-b7ee-c2fa11bd0dee",
   "metadata": {
    "id": "33f806ed-e9db-4199-b7ee-c2fa11bd0dee"
   },
   "outputs": [],
   "source": [
    "model_name = 'parallel_vit_dropout_changed'\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "## SEETING THE PATHS\n",
    "PATH_TO_CODE =''\n",
    "# PATH_TO_CODE ='/content/drive/MyDrive/TRIAL_v1/classification'\n",
    "sys.path.append(PATH_TO_CODE)\n",
    "# DATASET_PATH = r'/content/drive/MyDrive/TRIAL_v1/classification/data44_resized_splited'\n",
    "DATASET_PATH = r'data44_resized_splited'\n",
    "DATASET_PATH_TRAIN = os.path.join(DATASET_PATH, 'train')\n",
    "DATASET_PATH_TEST = os.path.join(DATASET_PATH, 'test')\n",
    "\n",
    "\n",
    "PATH_TO_SAVE_RESULT = os.path.join(PATH_TO_CODE, 'saved_outputs_basic_augment', model_name)\n",
    "PATH_BEST_SAVE_WEIGHT = os.path.join(PATH_TO_SAVE_RESULT,model_name+'_saved_weights')\n",
    "PATH_TO_SAVE_MODEL = os.path.join(PATH_TO_SAVE_RESULT, 'saved_models')\n",
    "PATH_SAVE_HISTORY = os.path.join(PATH_TO_SAVE_RESULT,model_name+'_training_history.csv')\n",
    "PATH_SAVE_TIME = os.path.join(PATH_TO_SAVE_RESULT, model_name+'_training_time.csv')\n",
    "\n",
    "\n",
    "if not os.path.exists(PATH_TO_SAVE_RESULT):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(PATH_TO_SAVE_RESULT)\n",
    "\n",
    "if not os.path.exists(PATH_BEST_SAVE_WEIGHT):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(PATH_BEST_SAVE_WEIGHT)\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200\n",
    "ORIGINAL_IMAGE_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "COLOR_CHANNEL = 3\n",
    "\n",
    "RESIZE_SHAPE = (128, 128)\n",
    "MODEL_INPUT_SIZE = (RESIZE_SHAPE[0], RESIZE_SHAPE[1], COLOR_CHANNEL)\n",
    "\n",
    "VALIDATION_SPLIT= 0.3\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 48\n",
    "\n",
    "################################################################################################\n",
    "AUGMENT = True\n",
    "AUGMENT_TYPE = 'basic' #'all'## basic, advanced,\n",
    "################################################################################################\n",
    "\n",
    "SAVE_RESULTS = True\n",
    "SHOW_RESULTS = True\n",
    "\n",
    "################################################################################################\n",
    "# Setting the seed\n",
    "SEED  = 123\n",
    "RNG = np.random.default_rng(SEED) # Random number generator\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "################################################################################################\n",
    "# Checkpoint parameters\n",
    "SCORE_TO_MONITOR = 'val_f1_score' # Score that checkpoints monitor during training\n",
    "SCORE_OBJECTIVE  = 'max'          # 'max' or 'min', specifies whether the objective is to maximize the score or minimize it.\n",
    "\n",
    "\n",
    "\n",
    "PATIENCE_EARLY_STOP = 12 # With no improvement in Loss, will stop training\n",
    "\n",
    "# # Checkpoint parameters\n",
    "REDUCTION_FACTOR = 0.5            # Factor which lr will be reduced with at plateau\n",
    "PATIENCE_LR_REDUCE=3      # Number of epochs with no improvement after which learning rate will be reduced\n",
    "COOLDOWN_EPOCHS  = 2              # How many epochs to wait after learning rate reduction before it can be reduced again\n",
    "MIN_LR = 1e-9\n",
    "INITIAL_LR = 0.0001 # with 0.001 got 99 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc029c0-dfb5-4571-a579-7fe7ca89cc2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1710546580214,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "5cc029c0-dfb5-4571-a579-7fe7ca89cc2a",
    "outputId": "43f824c2-c032-4d86-ab37-f4d842820b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_PATH data44_resized_splited\n",
      "DATASET_PATH_TRAIN data44_resized_splited\\train\n",
      "DATASET_PATH_TEST data44_resized_splited\\test\n",
      "PATH_SAVE_TIME  saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_training_time.csv\n",
      "PATH_SAVE_HISTORY saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_training_history.csv\n",
      "PATH_TO_SAVE_RESULT saved_outputs_basic_augment\\parallel_vit_dropout_changed\n",
      "PATH_BEST_SAVE_WEIGHT saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "PATH_TO_SAVE_MODEL saved_outputs_basic_augment\\parallel_vit_dropout_changed\\saved_models\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET_PATH\", DATASET_PATH)\n",
    "print(\"DATASET_PATH_TRAIN\", DATASET_PATH_TRAIN)\n",
    "print(\"DATASET_PATH_TEST\", DATASET_PATH_TEST)\n",
    "\n",
    "print(\"PATH_SAVE_TIME \", PATH_SAVE_TIME )\n",
    "print(\"PATH_SAVE_HISTORY\", PATH_SAVE_HISTORY)\n",
    "print(\"PATH_TO_SAVE_RESULT\",PATH_TO_SAVE_RESULT)\n",
    "print(\"PATH_BEST_SAVE_WEIGHT\", PATH_BEST_SAVE_WEIGHT)\n",
    "print(\"PATH_TO_SAVE_MODEL\", PATH_TO_SAVE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae2d29-d089-412a-88a5-7b5017dee4f8",
   "metadata": {
    "id": "60ae2d29-d089-412a-88a5-7b5017dee4f8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0f4e78e-2715-4ec6-b86d-a032075066a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1710546580214,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "d0f4e78e-2715-4ec6-b86d-a032075066a9",
    "outputId": "e1dcafe6-bd5c-4851-806d-5d2ea9ff8434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mahri\\AppData\\Local\\Temp\\ipykernel_8160\\984659479.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU Available:  True\n",
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30676387-9bdf-4015-83e8-db47734137d4",
   "metadata": {
    "id": "30676387-9bdf-4015-83e8-db47734137d4"
   },
   "source": [
    "## Image Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dada5c-1141-4914-96bd-a8ff36749e6d",
   "metadata": {
    "id": "69dada5c-1141-4914-96bd-a8ff36749e6d"
   },
   "source": [
    "### ElasticTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce2108f-7c14-40de-b590-d7e14856ae64",
   "metadata": {
    "id": "cce2108f-7c14-40de-b590-d7e14856ae64"
   },
   "outputs": [],
   "source": [
    "# Define an augmentation pipeline\n",
    "# Alpha parameter controls the intensity of the deformation\n",
    "# Sigma controls the smoothness of the deformation field.\n",
    "aug = iaa.Sequential([\n",
    "    iaa.ElasticTransformation(alpha=10, sigma=5)  # Apply elastic transformations , sigma=1\n",
    "])\n",
    "\n",
    "def elastic_deformation(image):\n",
    "    image_aug = aug(image=image)\n",
    "    return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e823091d-ce18-4444-845c-8a9bc459800a",
   "metadata": {
    "id": "e823091d-ce18-4444-845c-8a9bc459800a"
   },
   "outputs": [],
   "source": [
    "# Defining a function for creating the generators with given augmentation type\n",
    "def create_generators(dataset_path_train=DATASET_PATH_TRAIN,\n",
    "                      dataset_path_test=DATASET_PATH_TEST,\n",
    "                      valid_ratio=VALIDATION_SPLIT,\n",
    "                      augment= False,\n",
    "                      augment_type='basic'):\n",
    "\n",
    "    # If augmentation is True, apply data augmentation. Otherwise, only rescale.\n",
    "    if augment:\n",
    "        if augment_type == 'all':\n",
    "            datagen = ImageDataGenerator(\n",
    "                rescale=1./255, # Normalize images\n",
    "                validation_split=valid_ratio,  # Split ratio for validation set\n",
    "\n",
    "                # Geometric Transformations\n",
    "                rotation_range=10,  # degrees\n",
    "                width_shift_range=0.2,  # fraction of total width\n",
    "                height_shift_range=0.2,  # fraction of total height\n",
    "                shear_range=0.2,  # shear angle in counter-clockwise direction as radians\n",
    "                zoom_range=0.2,  # zoom range for random zoom\n",
    "                horizontal_flip=True,  # randomly flip images horizontally\n",
    "                # vertical_flip=True,  # randomly flip images vertically\n",
    "\n",
    "                # Pixel-Level Transformations\n",
    "                brightness_range=[0.8, 1.1],  # range for picking a brightness shift value\n",
    "                channel_shift_range=0.2,  # range for random channel shifts\n",
    "\n",
    "                # Advanced functions\n",
    "                preprocessing_function=elastic_deformation\n",
    "            )\n",
    "        elif augment_type == 'basic':\n",
    "            datagen = ImageDataGenerator(\n",
    "                rescale=1./255, # Normalize images\n",
    "                validation_split=valid_ratio,  # Split ratio for validation set\n",
    "\n",
    "                # Geometric Transformations\n",
    "                # rotation_range=10,  # degrees\n",
    "                zoom_range=0.2,  # zoom range for random zoom\n",
    "                # vertical_flip=True,  # randomly flip images vertically\n",
    "                horizontal_flip=True,  # randomly flip images horizontally\n",
    "            )\n",
    "    else:\n",
    "        # No augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            validation_split=valid_ratio,  # Split ratio for validation set\n",
    "            rescale=1./255, # Normalize images\n",
    "        )\n",
    "\n",
    "    # Create training generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        dataset_path_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seed = SEED,\n",
    "        class_mode=\"categorical\",  # Use \"categorical\" for multi-class classification\n",
    "        target_size=RESIZE_SHAPE,  # Adjust target size based on your model requirements\n",
    "        shuffle = True,\n",
    "        color_mode = 'rgb',\n",
    "        subset='training'  # Specify subset as 'training'\n",
    "    )\n",
    "\n",
    "    # Create validation generator\n",
    "    valid_generator = datagen.flow_from_directory(\n",
    "        dataset_path_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seed = SEED,\n",
    "        class_mode=\"categorical\",  # Use \"categorical\" for multi-class classification\n",
    "        target_size=RESIZE_SHAPE,  # Adjust target size based on your model requirements\n",
    "        shuffle = True,\n",
    "        color_mode = 'rgb',\n",
    "        subset='validation'  # Specify subset as 'validation'\n",
    "    )\n",
    "\n",
    "    # For the test set, assuming no augmentation, just rescaling\n",
    "    test_datagen = ImageDataGenerator(\n",
    "                rescale=1./255# Normalize images\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        dataset_path_test,\n",
    "        class_mode=\"categorical\",  # Use \"categorical\" for multi-class classification\n",
    "        target_size=RESIZE_SHAPE,  # Adjust target size based on your model requirements\n",
    "        seed = SEED,\n",
    "        shuffle = False,\n",
    "        color_mode = 'rgb',\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "    return train_generator, valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "269c38da-a92b-47d1-918c-3b19f84aa19c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13301,
     "status": "ok",
     "timestamp": 1710546593510,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "269c38da-a92b-47d1-918c-3b19f84aa19c",
    "outputId": "84016ace-2739-473f-9cc1-20c2fa18bb0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3324 images belonging to 4 classes.\n",
      "Found 1421 images belonging to 4 classes.\n",
      "Found 1187 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating the generators using functions\n",
    "train_generator, valid_generator, test_generator = create_generators(dataset_path_train=DATASET_PATH_TRAIN,\n",
    "                                                                     dataset_path_test = DATASET_PATH_TEST,\n",
    "                                                                     augment=AUGMENT,\n",
    "                                                                     augment_type = AUGMENT_TYPE,\n",
    "                                                                     valid_ratio = VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ca5e3-a160-4ee9-a451-3041c841fad9",
   "metadata": {
    "id": "da5ca5e3-a160-4ee9-a451-3041c841fad9"
   },
   "source": [
    "## Essential functions (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a25f3325-61a1-4d40-9672-f853c6f0d092",
   "metadata": {
    "id": "a25f3325-61a1-4d40-9672-f853c6f0d092"
   },
   "outputs": [],
   "source": [
    "def fit_and_save_best_model_vit(model_name, model, epochs=EPOCHS):\n",
    "    ##########################################################################################################\n",
    "\n",
    "    # Criteria for early stopping\n",
    "    EarlyStop_callback = EarlyStopping(min_delta=0.0001, patience=PATIENCE_EARLY_STOP, restore_best_weights=True)\n",
    "    ##########################################################################################################\n",
    "\n",
    "    # saved_best_weights = 'best_'+model_name+'_weights'\n",
    "    # PATH_BEST_WEIGHT_SAVE = os.path.join(PATH_BEST_SAVE_WEIGHT, saved_best_weights)\n",
    "    # Set up a model checkpoint to save the best model during training\n",
    "    best_weight_callback= ModelCheckpoint(filepath=PATH_BEST_SAVE_WEIGHT,\n",
    "                                          monitor=SCORE_TO_MONITOR,\n",
    "                                          save_best_only=True,\n",
    "                                          mode=SCORE_OBJECTIVE,\n",
    "                                          verbose=1,\n",
    "                                          save_weights_only=True )\n",
    "\n",
    "    ##########################################################################################################\n",
    "    # # Setup the ReduceLROnPlateau callback\n",
    "    reduce_LR = ReduceLROnPlateau(\n",
    "        factor=REDUCTION_FACTOR,      # Factor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "        patience=PATIENCE_LR_REDUCE,      # Number of epochs with no improvement after which learning rate will be reduced.\n",
    "        verbose=1,       # int. 0: quiet, 1: update messages.\n",
    "        min_lr=MIN_LR,   # Lower bound on the learning rate.\n",
    "        cooldown = COOLDOWN_EPOCHS\n",
    "    )\n",
    "\n",
    "    my_callbacks = [best_weight_callback , reduce_LR , EarlyStop_callback]\n",
    "    ##########################################################################################################\n",
    "    start_time = time.time()\n",
    "    # Fitting the model\n",
    "    train_history = model.fit(\n",
    "        train_generator,\n",
    "        epochs= epochs,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=valid_generator,\n",
    "        callbacks=my_callbacks,\n",
    "    )\n",
    "    total_time = time.time() -start_time\n",
    "    return  PATH_BEST_SAVE_WEIGHT, train_history , total_time, model#model_saving_path,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f7a2c-c72e-46d6-bdf6-ea7c300419c9",
   "metadata": {
    "id": "938f7a2c-c72e-46d6-bdf6-ea7c300419c9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Essential functions (saving result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b86f6126",
   "metadata": {
    "id": "b86f6126",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_history(training_history_object, list_of_metrics=None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        training_history_object:: Object returned by model.fit() function in keras\n",
    "        list_of_metrics        :: A list of metrics to be plotted. Use if you only\n",
    "                                  want to plot a subset of the total set of metrics\n",
    "                                  in the training history object. By Default it will\n",
    "                                  plot all of them in individual subplots.\n",
    "    \"\"\"\n",
    "    history_dict = training_history_object.history\n",
    "\n",
    "    ###################ADDDED NEW################################################\n",
    "    # Remove 'lr' and 'val_lr' keys from history_dict if they exist\n",
    "    history_dict.pop('lr', None)\n",
    "    history_dict.pop('val_lr', None)\n",
    "    #############################################################################\n",
    "\n",
    "    if list_of_metrics is None:\n",
    "        list_of_metrics = [key for key in list(history_dict.keys()) if 'val_' not in key]\n",
    "    trainHistDF = pd.DataFrame(history_dict)\n",
    "    # trainHistDF.head()\n",
    "    train_keys = list_of_metrics\n",
    "    valid_keys = ['val_' + key for key in train_keys]\n",
    "    nr_plots = len(train_keys)\n",
    "    fig, ax = plt.subplots(1,nr_plots,figsize=(5*nr_plots,4))\n",
    "    for i in range(len(train_keys)):\n",
    "        ax[i].plot(np.array(trainHistDF[train_keys[i]]), label='Training')\n",
    "        ax[i].plot(np.array(trainHistDF[valid_keys[i]]), label='Validation')\n",
    "        ax[i].set_xlabel('Epoch')\n",
    "        ax[i].set_title(train_keys[i])\n",
    "        ax[i].grid('on')\n",
    "        ax[i].legend()\n",
    "    fig.tight_layout\n",
    "    # plt.show()\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        # Save the plot to a PDF\n",
    "        pdf_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_training_history.pdf\")\n",
    "        with PdfPages(pdf_filename) as pdf:\n",
    "            pdf.savefig(fig)\n",
    "            if SHOW_RESULTS:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0848ff76-13fd-491e-bdda-546f69c4bd62",
   "metadata": {
    "id": "0848ff76-13fd-491e-bdda-546f69c4bd62"
   },
   "outputs": [],
   "source": [
    "def show_save_confusion_matrix(predicted_labels, target_labels):\n",
    "    cm = confusion_matrix(target_labels, predicted_labels)\n",
    "\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='g',  cmap='Greens')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    # plt.show()\n",
    "\n",
    "    # Save the plot to a PDF\n",
    "    if SAVE_RESULTS:\n",
    "        pdf_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_confusion_matrix.pdf\")\n",
    "        with PdfPages(pdf_filename) as pdf:\n",
    "            pdf.savefig()  # saves the current figure into a pdf page\n",
    "            # plt.close()\n",
    "            if SHOW_RESULTS:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d4d2fe-fff3-404e-9b5d-dcb57f615d7c",
   "metadata": {
    "id": "94d4d2fe-fff3-404e-9b5d-dcb57f615d7c"
   },
   "outputs": [],
   "source": [
    "def calculate_TF_TP_FP_FN(true_labels_y_test, predicted_labels):\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(true_labels_y_test, predicted_labels)\n",
    "\n",
    "    class_to_performance_data = {}\n",
    "    # Calculate TP, FP, TN, FN for each class\n",
    "    num_classes = cm.shape[0]\n",
    "    for cls in range(num_classes):\n",
    "        TP = cm[cls, cls]\n",
    "        FP = cm[:, cls].sum() - TP\n",
    "        FN = cm[cls, :].sum() - TP\n",
    "        TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "        # Calculate support for each class\n",
    "        support = TP + FN\n",
    "\n",
    "        class_to_performance_data[cls] = {'TP': TP, 'FP': FP, 'TN': TN, 'FN': FN, 'Support': support}\n",
    "    return class_to_performance_data\n",
    "\n",
    "\n",
    "def calculate_metrics(class_to_performance_data, accuracy, SHOW_RESULTS=True, SAVE_RESULTS=True):\n",
    "    metrics_summary = {\n",
    "        'overall':{},\n",
    "        'Macro': {},\n",
    "        'Weighted': {}\n",
    "    }\n",
    "\n",
    "    metrics_summary[ 'overall']= {'accuracy': accuracy}\n",
    "\n",
    "    # Lists to store metric values for macro averaging\n",
    "    precision_list, recall_list, f1_score_list = [], [], []\n",
    "    fpr_list, fnr_list, fdr_list, npv_list = [], [], [], []\n",
    "\n",
    "    # Variables for weighted sum of metrics\n",
    "    weighted_precision, weighted_recall, weighted_f1 = 0, 0, 0\n",
    "    weighted_fpr, weighted_fnr, weighted_fdr, weighted_npv = 0, 0, 0, 0\n",
    "    total_support = 0\n",
    "\n",
    "    # Calculate metrics for each class\n",
    "    for class_id, metrics in class_to_performance_data.items():\n",
    "        tp = metrics['TP']\n",
    "        fp = metrics['FP']\n",
    "        tn = metrics['TN']\n",
    "        fn = metrics['FN']\n",
    "        support = metrics['Support']\n",
    "\n",
    "        # Basic evaluation metrics\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        # Additional evaluation metrics\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        fnr = fn / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        fdr = fp / (fp + tp) if (fp + tp) > 0 else 0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "        # Append to lists for macro averaging\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1_score)\n",
    "        fpr_list.append(fpr)\n",
    "        fnr_list.append(fnr)\n",
    "        fdr_list.append(fdr)\n",
    "        npv_list.append(npv)\n",
    "\n",
    "        # Weighted sum of metrics\n",
    "        weighted_precision += precision * support\n",
    "        weighted_recall += recall * support\n",
    "        weighted_f1 += f1_score * support\n",
    "        weighted_fpr += fpr * support\n",
    "        weighted_fnr += fnr * support\n",
    "        weighted_fdr += fdr * support\n",
    "        weighted_npv += npv * support\n",
    "        total_support += support\n",
    "\n",
    "    # Calculate macro averages and round to 5 decimal places\n",
    "    metrics_summary['Macro']['Precision'] = round(sum(precision_list) / len(precision_list), 5)\n",
    "    metrics_summary['Macro']['Recall'] = round(sum(recall_list) / len(recall_list), 5)\n",
    "    metrics_summary['Macro']['F1-Score'] = round(sum(f1_score_list) / len(f1_score_list), 5)\n",
    "    metrics_summary['Macro']['FPR'] = round(sum(fpr_list) / len(fpr_list), 5)\n",
    "    metrics_summary['Macro']['FNR'] = round(sum(fnr_list) / len(fnr_list), 5)\n",
    "    metrics_summary['Macro']['FDR'] = round(sum(fdr_list) / len(fdr_list), 5)\n",
    "    metrics_summary['Macro']['NPV'] = round(sum(npv_list) / len(npv_list), 5)\n",
    "\n",
    "    # Calculate weighted averages and round to 5 decimal places\n",
    "    if total_support > 0:\n",
    "        metrics_summary['Weighted']['Precision'] = round(weighted_precision / total_support, 5)\n",
    "        metrics_summary['Weighted']['Recall'] = round(weighted_recall / total_support, 5)\n",
    "        metrics_summary['Weighted']['F1-Score'] = round(weighted_f1 / total_support, 5)\n",
    "        metrics_summary['Weighted']['FPR'] = round(weighted_fpr / total_support, 5)\n",
    "        metrics_summary['Weighted']['FNR'] = round(weighted_fnr / total_support, 5)\n",
    "        metrics_summary['Weighted']['FDR'] = round(weighted_fdr / total_support, 5)\n",
    "        metrics_summary['Weighted']['NPV'] = round(weighted_npv / total_support, 5)\n",
    "\n",
    "    # Convert the nested dictionary into a DataFrame\n",
    "    report_df = pd.DataFrame.from_dict({(i+\" \"+j): metrics_summary[i][j]  for i in metrics_summary.keys()  for j in metrics_summary[i].keys()}, orient='index').reset_index()\n",
    "    # Rename columns for clarity\n",
    "    report_df.columns = ['Metric Type', 'Value']\n",
    "    if SHOW_RESULTS:\n",
    "        display(report_df)\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        # if not os.path.exists(PATH_TO_SAVE_RESULT):\n",
    "        # # If it does not exist, create it\n",
    "        #     os.makedirs(PATH_TO_SAVE_RESULT)\n",
    "\n",
    "        prediction_report_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_all_performance_report.csv\" )\n",
    "        # Save the DataFrame to a CSV file\n",
    "        report_df.to_csv(prediction_report_filename, index=True)\n",
    "\n",
    "    # return metrics_summary\n",
    "\n",
    "def calculate_accuracy(true_labels_y_test, predicted_labels):\n",
    "    # Ensure the inputs are NumPy arrays for element-wise comparison\n",
    "    true_labels_y_test = np.array(true_labels_y_test)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "    # Calculate the number of correct predictions\n",
    "    correct_predictions = np.sum(true_labels_y_test == predicted_labels)\n",
    "\n",
    "    # Calculate the total number of predictions\n",
    "    total_predictions = len(true_labels_y_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "\n",
    "    # Round accuracy to 5 decimal places\n",
    "    accuracy = round(accuracy, 5)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11b63a55-74b4-4982-9feb-e6776d23f685",
   "metadata": {
    "id": "11b63a55-74b4-4982-9feb-e6776d23f685"
   },
   "outputs": [],
   "source": [
    "def store_classification_report(predicted_labels, target_labels):\n",
    "    report_dict = classification_report(target_labels, predicted_labels, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    if SHOW_RESULTS:\n",
    "        display(report_df)\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        prediction_report_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_classification_report.csv\" )\n",
    "        # Save the DataFrame to a CSV file\n",
    "        report_df.to_csv(prediction_report_filename, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56b36c2e-1a4a-4895-ba57-fa7fe0e6caa5",
   "metadata": {
    "id": "56b36c2e-1a4a-4895-ba57-fa7fe0e6caa5"
   },
   "outputs": [],
   "source": [
    "def show_save_test_results(test_generator, best_model):\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy, test_f1_score = best_model.evaluate(test_generator)\n",
    "\n",
    "    # print(f\"Test Loss: {test_loss}\")\n",
    "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
    "    # print(f\"Test F1 Score: {test_f1_score}\")\n",
    "\n",
    "    test_results = {\n",
    "        'model_name': model_name,\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_f1_score': test_f1_score\n",
    "    }\n",
    "\n",
    "        # Convert the dictionary to a DataFrame\n",
    "    report_df = pd.DataFrame([test_results])\n",
    "\n",
    "    if SHOW_RESULTS:\n",
    "        display(report_df)\n",
    "\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        path_to_save = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_model_performance.csv\")\n",
    "        # Save the DataFrame to a CSV file\n",
    "        report_df.to_csv(path_to_save , index=False)\n",
    "        del report_df, test_results\n",
    "    return  test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2181fbed-1eed-4090-81b7-32e7b309aebf",
   "metadata": {
    "id": "2181fbed-1eed-4090-81b7-32e7b309aebf"
   },
   "outputs": [],
   "source": [
    "def calculate_test_performance_metrics_all(predicted_labels, target_labels, test_loss):\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(target_labels, predicted_labels)\n",
    "    precision_macro = precision_score(target_labels, predicted_labels, average='macro')\n",
    "    recall_macro = recall_score(target_labels, predicted_labels, average='macro')\n",
    "    f1_macro = f1_score_report(target_labels, predicted_labels, average='macro')\n",
    "\n",
    "    precision_weighted = precision_score(target_labels, predicted_labels, average='weighted')\n",
    "    recall_weighted = recall_score(target_labels, predicted_labels, average='weighted')\n",
    "    f1_weighted = f1_score_report(target_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    # Create a dictionary to hold the metrics\n",
    "    test_results = {\n",
    "        'Model Name': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Macro Precision': precision_macro,\n",
    "        'Macro Recall': recall_macro,\n",
    "        'Macro F1-Score': f1_macro,\n",
    "        'Weighted Precision': precision_weighted,\n",
    "        'Weighted Recall': recall_weighted,\n",
    "        'Weighted F1-Score': f1_weighted,\n",
    "        'Loss': test_loss\n",
    "    }\n",
    "\n",
    "        # Convert the dictionary to a DataFrame\n",
    "    report_df = pd.DataFrame([test_results])\n",
    "\n",
    "    if SHOW_RESULTS:\n",
    "        display(report_df)\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        path_to_save = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_model_all_test_performance.csv\")\n",
    "        # Save the DataFrame to a CSV file\n",
    "        report_df.to_csv(path_to_save , index=False)\n",
    "\n",
    "    del report_df, test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3608cfb",
   "metadata": {
    "id": "f3608cfb"
   },
   "source": [
    "# MODEL CREATING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd7a6b-3ba9-4754-af22-fa0aff5bad4e",
   "metadata": {
    "id": "dfdd7a6b-3ba9-4754-af22-fa0aff5bad4e"
   },
   "source": [
    "### Original Vit models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93a29d72-21e4-43ff-bb74-ac9d51d0e020",
   "metadata": {
    "id": "93a29d72-21e4-43ff-bb74-ac9d51d0e020"
   },
   "outputs": [],
   "source": [
    "from parallel_vit import ViT as parallelViT\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "def get_parallel_vit():\n",
    "\n",
    "    model = parallelViT(\n",
    "    image_size = max(MODEL_INPUT_SIZE[0], MODEL_INPUT_SIZE[1]),\n",
    "    patch_size = 16,\n",
    "    num_classes = NUM_CLASSES,\n",
    "    dim = 512, #original 1024\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 1024, # original 2048\n",
    "    num_parallel_branches = 2,  # in paper, they claimed 2 was optimal\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "\n",
    "    optimizer = Adam(learning_rate=INITIAL_LR)\n",
    "    model.compile(loss=CategoricalCrossentropy(from_logits=True),\n",
    "                  run_eagerly=True,\n",
    "                  metrics=['accuracy', f1_score],\n",
    "                  optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6308b58-680e-434c-ae75-07ea53e2cad2",
   "metadata": {
    "id": "f6308b58-680e-434c-ae75-07ea53e2cad2"
   },
   "source": [
    "# Train and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06642652-4393-4874-b0eb-e5fed0234b00",
   "metadata": {
    "id": "06642652-4393-4874-b0eb-e5fed0234b00"
   },
   "outputs": [],
   "source": [
    "# if model_name=='DenseNet121':\n",
    "#     model= get_DenseNet121()\n",
    "# elif model_name=='MobileNet':\n",
    "#     model= get_MobileNet_original()\n",
    "# elif model_name=='Xception':\n",
    "#     model= get_Xception()\n",
    "# elif model_name=='InceptionV3':\n",
    "#     model= get_InceptionV3()\n",
    "\n",
    "# ##Getting the model\n",
    "# model= get_MobileNet_original()\n",
    "# model= get_DenseNet121()\n",
    "# model= get_Xception()\n",
    "# model= get_InceptionV3()\n",
    "# model = get_cait()\n",
    "# # ## Getting the model\n",
    "# model = get_basic_CNN()\n",
    "# model = get_ensemble2_model()\n",
    "# model = get_original_vit()\n",
    "model = get_parallel_vit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65eeabc6-ab0f-4054-ae45-9a8e2d7d2294",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2715398,
     "status": "ok",
     "timestamp": 1710549356974,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "65eeabc6-ab0f-4054-ae45-9a8e2d7d2294",
    "outputId": "c7b0f53c-869f-4016-ab8a-4a053f4a466a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 1.8744 - accuracy: 0.2861 - f1_score: 0.2812\n",
      "Epoch 1: val_f1_score improved from -inf to 0.35278, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 109s 2s/step - loss: 1.8744 - accuracy: 0.2861 - f1_score: 0.2812 - val_loss: 1.2500 - val_accuracy: 0.4518 - val_f1_score: 0.3528 - lr: 1.0000e-04\n",
      "Epoch 2/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 1.2220 - accuracy: 0.4320 - f1_score: 0.4258\n",
      "Epoch 2: val_f1_score did not improve from 0.35278\n",
      "52/52 [==============================] - 103s 2s/step - loss: 1.2220 - accuracy: 0.4320 - f1_score: 0.4258 - val_loss: 1.2992 - val_accuracy: 0.4243 - val_f1_score: 0.3426 - lr: 1.0000e-04\n",
      "Epoch 3/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 1.0721 - accuracy: 0.5623 - f1_score: 0.5537\n",
      "Epoch 3: val_f1_score improved from 0.35278 to 0.62879, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 101s 2s/step - loss: 1.0721 - accuracy: 0.5623 - f1_score: 0.5537 - val_loss: 0.9960 - val_accuracy: 0.6383 - val_f1_score: 0.6288 - lr: 1.0000e-04\n",
      "Epoch 4/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.8753 - accuracy: 0.6694 - f1_score: 0.6660\n",
      "Epoch 4: val_f1_score did not improve from 0.62879\n",
      "52/52 [==============================] - 103s 2s/step - loss: 0.8753 - accuracy: 0.6694 - f1_score: 0.6660 - val_loss: 1.0479 - val_accuracy: 0.6080 - val_f1_score: 0.5825 - lr: 1.0000e-04\n",
      "Epoch 5/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.8019 - accuracy: 0.6949 - f1_score: 0.6936\n",
      "Epoch 5: val_f1_score improved from 0.62879 to 0.72443, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 107s 2s/step - loss: 0.8019 - accuracy: 0.6949 - f1_score: 0.6936 - val_loss: 0.7204 - val_accuracy: 0.7255 - val_f1_score: 0.7244 - lr: 1.0000e-04\n",
      "Epoch 6/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.7026 - accuracy: 0.7383 - f1_score: 0.7398\n",
      "Epoch 6: val_f1_score improved from 0.72443 to 0.72809, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 108s 2s/step - loss: 0.7026 - accuracy: 0.7383 - f1_score: 0.7398 - val_loss: 0.6465 - val_accuracy: 0.7368 - val_f1_score: 0.7281 - lr: 1.0000e-04\n",
      "Epoch 7/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.7289 - f1_score: 0.7299\n",
      "Epoch 7: val_f1_score did not improve from 0.72809\n",
      "52/52 [==============================] - 104s 2s/step - loss: 0.6968 - accuracy: 0.7289 - f1_score: 0.7299 - val_loss: 0.7201 - val_accuracy: 0.7234 - val_f1_score: 0.7236 - lr: 1.0000e-04\n",
      "Epoch 8/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.7566 - f1_score: 0.7591\n",
      "Epoch 8: val_f1_score improved from 0.72809 to 0.79167, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 114s 2s/step - loss: 0.6081 - accuracy: 0.7566 - f1_score: 0.7591 - val_loss: 0.5252 - val_accuracy: 0.7896 - val_f1_score: 0.7917 - lr: 1.0000e-04\n",
      "Epoch 9/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.7939 - f1_score: 0.7961\n",
      "Epoch 9: val_f1_score did not improve from 0.79167\n",
      "52/52 [==============================] - 112s 2s/step - loss: 0.5124 - accuracy: 0.7939 - f1_score: 0.7961 - val_loss: 1.1045 - val_accuracy: 0.6594 - val_f1_score: 0.6428 - lr: 1.0000e-04\n",
      "Epoch 10/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.7939 - f1_score: 0.7962\n",
      "Epoch 10: val_f1_score did not improve from 0.79167\n",
      "52/52 [==============================] - 107s 2s/step - loss: 0.5143 - accuracy: 0.7939 - f1_score: 0.7962 - val_loss: 0.6181 - val_accuracy: 0.7783 - val_f1_score: 0.7782 - lr: 1.0000e-04\n",
      "Epoch 11/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8496 - f1_score: 0.8513\n",
      "Epoch 11: val_f1_score improved from 0.79167 to 0.87017, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 121s 2s/step - loss: 0.3823 - accuracy: 0.8496 - f1_score: 0.8513 - val_loss: 0.3286 - val_accuracy: 0.8691 - val_f1_score: 0.8702 - lr: 1.0000e-04\n",
      "Epoch 12/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3943 - accuracy: 0.8439 - f1_score: 0.8458\n",
      "Epoch 12: val_f1_score did not improve from 0.87017\n",
      "52/52 [==============================] - 119s 2s/step - loss: 0.3943 - accuracy: 0.8439 - f1_score: 0.8458 - val_loss: 0.4525 - val_accuracy: 0.8311 - val_f1_score: 0.8356 - lr: 1.0000e-04\n",
      "Epoch 13/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.8727 - f1_score: 0.8745\n",
      "Epoch 13: val_f1_score improved from 0.87017 to 0.92091, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 118s 2s/step - loss: 0.3308 - accuracy: 0.8727 - f1_score: 0.8745 - val_loss: 0.2388 - val_accuracy: 0.9198 - val_f1_score: 0.9209 - lr: 1.0000e-04\n",
      "Epoch 14/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.9028 - f1_score: 0.9039\n",
      "Epoch 14: val_f1_score did not improve from 0.92091\n",
      "52/52 [==============================] - 110s 2s/step - loss: 0.2435 - accuracy: 0.9028 - f1_score: 0.9039 - val_loss: 0.2643 - val_accuracy: 0.8951 - val_f1_score: 0.8975 - lr: 1.0000e-04\n",
      "Epoch 15/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.9001 - f1_score: 0.9009\n",
      "Epoch 15: val_f1_score did not improve from 0.92091\n",
      "52/52 [==============================] - 115s 2s/step - loss: 0.2579 - accuracy: 0.9001 - f1_score: 0.9009 - val_loss: 0.2720 - val_accuracy: 0.8881 - val_f1_score: 0.8884 - lr: 1.0000e-04\n",
      "Epoch 16/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.9091 - f1_score: 0.9101\n",
      "Epoch 16: val_f1_score did not improve from 0.92091\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "52/52 [==============================] - 123s 2s/step - loss: 0.2411 - accuracy: 0.9091 - f1_score: 0.9101 - val_loss: 0.2929 - val_accuracy: 0.9092 - val_f1_score: 0.9105 - lr: 1.0000e-04\n",
      "Epoch 17/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.9338 - f1_score: 0.9350\n",
      "Epoch 17: val_f1_score improved from 0.92091 to 0.95501, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 127s 2s/step - loss: 0.1709 - accuracy: 0.9338 - f1_score: 0.9350 - val_loss: 0.1185 - val_accuracy: 0.9543 - val_f1_score: 0.9550 - lr: 5.0000e-05\n",
      "Epoch 18/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9549 - f1_score: 0.9556\n",
      "Epoch 18: val_f1_score did not improve from 0.95501\n",
      "52/52 [==============================] - 128s 2s/step - loss: 0.1207 - accuracy: 0.9549 - f1_score: 0.9556 - val_loss: 0.2200 - val_accuracy: 0.9198 - val_f1_score: 0.9200 - lr: 5.0000e-05\n",
      "Epoch 19/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9627 - f1_score: 0.9633\n",
      "Epoch 19: val_f1_score improved from 0.95501 to 0.95769, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 127s 2s/step - loss: 0.0992 - accuracy: 0.9627 - f1_score: 0.9633 - val_loss: 0.1295 - val_accuracy: 0.9571 - val_f1_score: 0.9577 - lr: 5.0000e-05\n",
      "Epoch 20/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9744 - f1_score: 0.9750\n",
      "Epoch 20: val_f1_score improved from 0.95769 to 0.96799, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 135s 3s/step - loss: 0.0754 - accuracy: 0.9744 - f1_score: 0.9750 - val_loss: 0.0822 - val_accuracy: 0.9669 - val_f1_score: 0.9680 - lr: 5.0000e-05\n",
      "Epoch 21/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9735 - f1_score: 0.9739\n",
      "Epoch 21: val_f1_score improved from 0.96799 to 0.97312, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 135s 3s/step - loss: 0.0735 - accuracy: 0.9735 - f1_score: 0.9739 - val_loss: 0.0705 - val_accuracy: 0.9726 - val_f1_score: 0.9731 - lr: 5.0000e-05\n",
      "Epoch 22/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9750 - f1_score: 0.9754\n",
      "Epoch 22: val_f1_score did not improve from 0.97312\n",
      "52/52 [==============================] - 133s 3s/step - loss: 0.0714 - accuracy: 0.9750 - f1_score: 0.9754 - val_loss: 0.1415 - val_accuracy: 0.9493 - val_f1_score: 0.9500 - lr: 5.0000e-05\n",
      "Epoch 23/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9735 - f1_score: 0.9739\n",
      "Epoch 23: val_f1_score did not improve from 0.97312\n",
      "52/52 [==============================] - 138s 3s/step - loss: 0.0695 - accuracy: 0.9735 - f1_score: 0.9739 - val_loss: 0.0763 - val_accuracy: 0.9711 - val_f1_score: 0.9713 - lr: 5.0000e-05\n",
      "Epoch 24/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9759 - f1_score: 0.9763\n",
      "Epoch 24: val_f1_score did not improve from 0.97312\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "52/52 [==============================] - 135s 3s/step - loss: 0.0630 - accuracy: 0.9759 - f1_score: 0.9763 - val_loss: 0.0794 - val_accuracy: 0.9704 - val_f1_score: 0.9708 - lr: 5.0000e-05\n",
      "Epoch 25/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9895 - f1_score: 0.9897\n",
      "Epoch 25: val_f1_score improved from 0.97312 to 0.98479, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 142s 3s/step - loss: 0.0324 - accuracy: 0.9895 - f1_score: 0.9897 - val_loss: 0.0412 - val_accuracy: 0.9845 - val_f1_score: 0.9848 - lr: 2.5000e-05\n",
      "Epoch 26/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9904 - f1_score: 0.9904\n",
      "Epoch 26: val_f1_score improved from 0.98479 to 0.99720, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 145s 3s/step - loss: 0.0293 - accuracy: 0.9904 - f1_score: 0.9904 - val_loss: 0.0127 - val_accuracy: 0.9972 - val_f1_score: 0.9972 - lr: 2.5000e-05\n",
      "Epoch 27/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9895 - f1_score: 0.9897\n",
      "Epoch 27: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 142s 3s/step - loss: 0.0290 - accuracy: 0.9895 - f1_score: 0.9897 - val_loss: 0.0407 - val_accuracy: 0.9859 - val_f1_score: 0.9863 - lr: 2.5000e-05\n",
      "Epoch 28/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9919 - f1_score: 0.9921\n",
      "Epoch 28: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 142s 3s/step - loss: 0.0261 - accuracy: 0.9919 - f1_score: 0.9921 - val_loss: 0.0727 - val_accuracy: 0.9733 - val_f1_score: 0.9736 - lr: 2.5000e-05\n",
      "Epoch 29/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9940 - f1_score: 0.9941\n",
      "Epoch 29: val_f1_score did not improve from 0.99720\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "52/52 [==============================] - 143s 3s/step - loss: 0.0225 - accuracy: 0.9940 - f1_score: 0.9941 - val_loss: 0.0330 - val_accuracy: 0.9894 - val_f1_score: 0.9896 - lr: 2.5000e-05\n",
      "Epoch 30/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9946 - f1_score: 0.9947\n",
      "Epoch 30: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 137s 3s/step - loss: 0.0199 - accuracy: 0.9946 - f1_score: 0.9947 - val_loss: 0.0166 - val_accuracy: 0.9944 - val_f1_score: 0.9944 - lr: 1.2500e-05\n",
      "Epoch 31/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9961 - f1_score: 0.9962\n",
      "Epoch 31: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 147s 3s/step - loss: 0.0146 - accuracy: 0.9961 - f1_score: 0.9962 - val_loss: 0.0166 - val_accuracy: 0.9958 - val_f1_score: 0.9959 - lr: 1.2500e-05\n",
      "Epoch 32/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9931 - f1_score: 0.9931\n",
      "Epoch 32: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 150s 3s/step - loss: 0.0198 - accuracy: 0.9931 - f1_score: 0.9931 - val_loss: 0.0430 - val_accuracy: 0.9845 - val_f1_score: 0.9846 - lr: 1.2500e-05\n",
      "Epoch 33/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9964 - f1_score: 0.9965\n",
      "Epoch 33: val_f1_score did not improve from 0.99720\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "52/52 [==============================] - 153s 3s/step - loss: 0.0138 - accuracy: 0.9964 - f1_score: 0.9965 - val_loss: 0.0276 - val_accuracy: 0.9901 - val_f1_score: 0.9903 - lr: 1.2500e-05\n",
      "Epoch 34/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9973 - f1_score: 0.9974\n",
      "Epoch 34: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 150s 3s/step - loss: 0.0119 - accuracy: 0.9973 - f1_score: 0.9974 - val_loss: 0.0236 - val_accuracy: 0.9916 - val_f1_score: 0.9917 - lr: 6.2500e-06\n",
      "Epoch 35/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9982 - f1_score: 0.9983\n",
      "Epoch 35: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 159s 3s/step - loss: 0.0091 - accuracy: 0.9982 - f1_score: 0.9983 - val_loss: 0.0181 - val_accuracy: 0.9930 - val_f1_score: 0.9931 - lr: 6.2500e-06\n",
      "Epoch 36/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9973 - f1_score: 0.9973\n",
      "Epoch 36: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 161s 3s/step - loss: 0.0111 - accuracy: 0.9973 - f1_score: 0.9973 - val_loss: 0.0113 - val_accuracy: 0.9958 - val_f1_score: 0.9959 - lr: 6.2500e-06\n",
      "Epoch 37/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9979 - f1_score: 0.9980\n",
      "Epoch 37: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 159s 3s/step - loss: 0.0097 - accuracy: 0.9979 - f1_score: 0.9980 - val_loss: 0.0212 - val_accuracy: 0.9930 - val_f1_score: 0.9931 - lr: 6.2500e-06\n",
      "Epoch 38/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9970 - f1_score: 0.9970\n",
      "Epoch 38: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 168s 3s/step - loss: 0.0116 - accuracy: 0.9970 - f1_score: 0.9970 - val_loss: 0.0179 - val_accuracy: 0.9930 - val_f1_score: 0.9931 - lr: 6.2500e-06\n",
      "Epoch 39/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9976 - f1_score: 0.9977\n",
      "Epoch 39: val_f1_score did not improve from 0.99720\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "52/52 [==============================] - 162s 3s/step - loss: 0.0101 - accuracy: 0.9976 - f1_score: 0.9977 - val_loss: 0.0224 - val_accuracy: 0.9916 - val_f1_score: 0.9917 - lr: 6.2500e-06\n",
      "Epoch 40/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9970 - f1_score: 0.9971\n",
      "Epoch 40: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 172s 3s/step - loss: 0.0122 - accuracy: 0.9970 - f1_score: 0.9971 - val_loss: 0.0284 - val_accuracy: 0.9887 - val_f1_score: 0.9889 - lr: 3.1250e-06\n",
      "Epoch 41/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9961 - f1_score: 0.9961\n",
      "Epoch 41: val_f1_score did not improve from 0.99720\n",
      "52/52 [==============================] - 176s 3s/step - loss: 0.0113 - accuracy: 0.9961 - f1_score: 0.9961 - val_loss: 0.0181 - val_accuracy: 0.9930 - val_f1_score: 0.9930 - lr: 3.1250e-06\n",
      "Epoch 42/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9958 - f1_score: 0.9958\n",
      "Epoch 42: val_f1_score improved from 0.99720 to 0.99722, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 190s 4s/step - loss: 0.0118 - accuracy: 0.9958 - f1_score: 0.9958 - val_loss: 0.0145 - val_accuracy: 0.9972 - val_f1_score: 0.9972 - lr: 3.1250e-06\n",
      "Epoch 43/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9955 - f1_score: 0.9956\n",
      "Epoch 43: val_f1_score did not improve from 0.99722\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "52/52 [==============================] - 196s 4s/step - loss: 0.0132 - accuracy: 0.9955 - f1_score: 0.9956 - val_loss: 0.0153 - val_accuracy: 0.9958 - val_f1_score: 0.9958 - lr: 3.1250e-06\n",
      "Epoch 44/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9985 - f1_score: 0.9985\n",
      "Epoch 44: val_f1_score did not improve from 0.99722\n",
      "52/52 [==============================] - 196s 4s/step - loss: 0.0078 - accuracy: 0.9985 - f1_score: 0.9985 - val_loss: 0.0217 - val_accuracy: 0.9937 - val_f1_score: 0.9937 - lr: 1.5625e-06\n",
      "Epoch 45/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9976 - f1_score: 0.9976\n",
      "Epoch 45: val_f1_score did not improve from 0.99722\n",
      "52/52 [==============================] - 193s 4s/step - loss: 0.0088 - accuracy: 0.9976 - f1_score: 0.9976 - val_loss: 0.0222 - val_accuracy: 0.9930 - val_f1_score: 0.9930 - lr: 1.5625e-06\n",
      "Epoch 46/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973 - f1_score: 0.9974\n",
      "Epoch 46: val_f1_score improved from 0.99722 to 0.99795, saving model to saved_outputs_basic_augment\\parallel_vit_dropout_changed\\parallel_vit_dropout_changed_saved_weights\n",
      "52/52 [==============================] - 199s 4s/step - loss: 0.0089 - accuracy: 0.9973 - f1_score: 0.9974 - val_loss: 0.0087 - val_accuracy: 0.9979 - val_f1_score: 0.9980 - lr: 1.5625e-06\n",
      "Epoch 47/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9973 - f1_score: 0.9974\n",
      "Epoch 47: val_f1_score did not improve from 0.99795\n",
      "52/52 [==============================] - 190s 4s/step - loss: 0.0104 - accuracy: 0.9973 - f1_score: 0.9974 - val_loss: 0.0176 - val_accuracy: 0.9937 - val_f1_score: 0.9937 - lr: 1.5625e-06\n",
      "Epoch 48/48\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9970 - f1_score: 0.9971\n",
      "Epoch 48: val_f1_score did not improve from 0.99795\n",
      "52/52 [==============================] - 197s 4s/step - loss: 0.0088 - accuracy: 0.9970 - f1_score: 0.9971 - val_loss: 0.0124 - val_accuracy: 0.9958 - val_f1_score: 0.9959 - lr: 1.5625e-06\n"
     ]
    }
   ],
   "source": [
    "# training the model and saving the best model as a check point\n",
    "PATH_BEST_WEIGHT_SAVE, train_history , total_time, best_model = fit_and_save_best_model_vit(model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3b68166-6085-47f2-a43a-20152cef8268",
   "metadata": {
    "id": "c3b68166-6085-47f2-a43a-20152cef8268"
   },
   "outputs": [],
   "source": [
    "# best_model= get_parallel_vit()\n",
    "\n",
    "# best_model.load_weights(\"saved_models_basic_augment\\\\parallel_vit_dropout_changed_TAKE\\\\parallel_vit_dropout_changed_saved_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a71ec9d2-c3fc-4343-ad66-42d582449842",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6502,
     "status": "ok",
     "timestamp": 1710549846747,
     "user": {
      "displayName": "Mahrin Mehrin",
      "userId": "03538273846602354774"
     },
     "user_tz": -60
    },
    "id": "a71ec9d2-c3fc-4343-ad66-42d582449842",
    "outputId": "0ce4334f-e4e9-4d0a-f2ed-49e678eb13d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 23s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from the model\n",
    "predictions = best_model.predict(test_generator, verbose=1)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_labels_y_test =  np.array(test_generator.classes) # y_test\n",
    "############################################################################################################]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc406f1b-30be-4de5-a87c-7591b1214de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrapped Macro AUC (100 runs):\n",
      "Mean AUC     : 0.99961\n",
      "Std Deviation: 0.00018\n",
      "95% CI       : (0.99923, 0.99988)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9996108547058499,\n",
       " 0.00018242952475172583,\n",
       " (0.9992251831992514, 0.9998846643992383))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def bootstrap_auc_ci(true_labels, predicted_probs, num_classes=NUM_CLASSES, n_iterations=100, seed=SEED, save_path=None):\n",
    "    \"\"\"\n",
    "    Computes bootstrapped AUC with 95% confidence interval for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.array): Ground truth class labels (e.g., [0, 1, 2, ...])\n",
    "        predicted_probs (np.array): Predicted probabilities, shape = (n_samples, n_classes)\n",
    "        num_classes (int): Number of classes\n",
    "        n_iterations (int): Number of bootstrap iterations\n",
    "        seed (int): Random seed for reproducibility\n",
    "        save_path (str): Optional path to save AUC scores as CSV\n",
    "\n",
    "    Returns:\n",
    "        Prints mean AUC, std, and 95% CI\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    auc_scores = []\n",
    "\n",
    "    # One-hot encode true labels\n",
    "    true_labels_bin = label_binarize(true_labels, classes=np.arange(num_classes))\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        indices = np.random.choice(len(true_labels), size=len(true_labels), replace=True)\n",
    "        y_true_sample = true_labels_bin[indices]\n",
    "        y_pred_sample = predicted_probs[indices]\n",
    "\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true_sample, y_pred_sample, multi_class='ovr', average='macro')\n",
    "            auc_scores.append(auc)\n",
    "        except ValueError:\n",
    "            continue  # Skip if a class is missing in the sample\n",
    "\n",
    "    auc_scores = np.array(auc_scores)\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    std_auc = np.std(auc_scores)\n",
    "    ci_lower = np.percentile(auc_scores, 2.5)\n",
    "    ci_upper = np.percentile(auc_scores, 97.5)\n",
    "\n",
    "    print(f\"\\nBootstrapped Macro AUC ({n_iterations} runs):\")\n",
    "    print(f\"Mean AUC     : {mean_auc:.5f}\")\n",
    "    print(f\"Std Deviation: {std_auc:.5f}\")\n",
    "    print(f\"95% CI       : ({ci_lower:.5f}, {ci_upper:.5f})\")\n",
    "\n",
    "    if save_path:\n",
    "        df = pd.DataFrame({'AUC Score': auc_scores})\n",
    "        df.to_csv(save_path, index=False)\n",
    "\n",
    "    return mean_auc, std_auc, (ci_lower, ci_upper)\n",
    "\n",
    "# Call the function\n",
    "bootstrap_auc_ci(\n",
    "    true_labels=true_labels_y_test,\n",
    "    predicted_probs=predictions,\n",
    "    save_path=os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_bootstrapped_auc.csv\")\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "69dada5c-1141-4914-96bd-a8ff36749e6d",
    "da5ca5e3-a160-4ee9-a451-3041c841fad9",
    "938f7a2c-c72e-46d6-bdf6-ea7c300419c9",
    "F0UlityPEMxc",
    "3xZyTkwcDeE2",
    "esq3i0AwDhYD",
    "TU7_2IfFDkbP",
    "-PiTU6R0Dq6y",
    "usVCdrmaDvxw",
    "dfdd7a6b-3ba9-4754-af22-fa0aff5bad4e"
   ],
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-13T13:42:48.933576",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
