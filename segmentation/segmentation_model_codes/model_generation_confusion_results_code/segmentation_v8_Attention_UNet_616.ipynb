{"cells":[{"cell_type":"markdown","id":"c4f40068-3bd2-4464-8c10-1ae560f13570","metadata":{"id":"c4f40068-3bd2-4464-8c10-1ae560f13570"},"source":["## Importing necessary modules"]},{"cell_type":"code","execution_count":null,"id":"pcyiTh4DiVge","metadata":{"id":"pcyiTh4DiVge"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"fa64290b-2570-4f24-920a-07a72a3660b9","metadata":{"id":"fa64290b-2570-4f24-920a-07a72a3660b9"},"outputs":[],"source":["import time\n","from tqdm import tqdm # Cool progress bar\n","\n","import random\n","import numpy as np\n","import pandas as pd\n","import sys\n","import os # read and manipulate local files\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","import cv2\n","import seaborn as sns\n","\n","from PIL import Image\n","\n","import tensorflow.keras as ks\n","import tensorflow as tf\n","\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import backend as K # F1-score metric\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.layers import   Lambda, Conv2D, MaxPool2D, UpSampling2D, BatchNormalization, Flatten\n","from tensorflow.keras.layers import  GlobalAveragePooling2D, Reshape, Multiply, Attention, add,Resizing,  Input, Dense\n","from tensorflow.keras.layers import Activation,AveragePooling2D, MaxPooling2D, Dropout, Conv2DTranspose, Concatenate\n","from tensorflow.keras.models import Model, Sequential\n","\n","# hide wornings\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","from imgaug import augmenters as iaa ## for augmentation"]},{"cell_type":"markdown","id":"bb6fe714-f8fb-4f9d-9657-ca3373fd9779","metadata":{"id":"bb6fe714-f8fb-4f9d-9657-ca3373fd9779"},"source":["## Defining paths"]},{"cell_type":"code","execution_count":null,"id":"051a2f6e-d46f-44ae-bfce-e2eb91954b5f","metadata":{"id":"051a2f6e-d46f-44ae-bfce-e2eb91954b5f"},"outputs":[],"source":["model_name = 'Attention_UNet_616'\n","\n","################################################################################################\n","## SETTING THE PATHS\n","PATH_TO_CODE ='/content/drive/MyDrive/TRIAL_v1/segmentation_task'\n","# PATH_TO_CODE =''\n","sys.path.append(PATH_TO_CODE)\n","\n","# DATASET_PATH = r'C:\\Users\\ASUS\\Desktop\\segmentation & cropping\\segmentation_task\\segmentation_data43_resized_cropped_split'\n","DATASET_PATH = r'/content/drive/MyDrive/TRIAL_v1/segmentation_task/segmentation_data43_resized_cropped_split'\n","# DATASET_PATH = r'segmentation_data43_resized_cropped_split'\n","DATASET_PATH_TRAIN = os.path.join(DATASET_PATH, 'train')\n","DATASET_PATH_TEST = os.path.join(DATASET_PATH, 'test')\n","\n","\n","PATH_TO_SAVE_RESULT = os.path.join(PATH_TO_CODE, 'saved_outputs_segmentation', model_name)\n","PATH_BEST_SAVE_WEIGHT = os.path.join(PATH_TO_SAVE_RESULT,'saved_weights')\n","PATH_TO_SAVE_MODEL = os.path.join(PATH_TO_SAVE_RESULT, 'saved_models')\n","PATH_SAVE_HISTORY = os.path.join(PATH_TO_SAVE_RESULT, model_name+'_training_history.csv')\n","PATH_SAVE_TIME = os.path.join(PATH_TO_SAVE_RESULT, model_name+'_training_time.csv')\n","PATH_SAVE_AUGMENT_SAMPLE = os.path.join(PATH_TO_SAVE_RESULT, model_name+'_augmented_sample.pdf')\n","PATH_SAVE_PIXEL_PERCENTAGE_PLOT = os.path.join(PATH_TO_SAVE_RESULT, model_name+'_pixel_percentage.pdf')\n","# PATH_TO_SAVE_TUNER = os.path.join(PATH_TO_RESULT, 'saved_tuner_model')\n","################################################################################################\n","\n","if not os.path.exists(PATH_TO_SAVE_RESULT):\n"," # If it does not exist, create it\n","    os.makedirs(PATH_TO_SAVE_RESULT)\n","################################################################################################\n","IMG_HEIGHT = 256\n","IMG_WIDTH = 256\n","ORIGINAL_IMAGE_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n","COLOR_CHANNEL = 3\n","\n","RESIZE_SHAPE = ORIGINAL_IMAGE_SIZE #(128, 128) #ORIGINAL_IMAGE_SIZE#(128, 128)# # #ORIGINAL_IMAGE_SIZE# (128, 128)#\n","MODEL_INPUT_SIZE = (RESIZE_SHAPE[0], RESIZE_SHAPE[1], COLOR_CHANNEL)\n","\n","VALIDATION_SPLIT= 0.2\n","NUM_CLASSES = 2 # Disease and not disease\n","\n","BATCH_SIZE = 10\n","EPOCHS = 33#80#100\n","\n","TOTAL_DATA = 616\n","################################################################################################\n","\n","################################################################################################\n","\n","SAVE_RESULTS = True\n","SHOW_RESULTS = True\n","\n","################################################################################################\n","# Setting the seed\n","SEED  = 123\n","RNG = np.random.default_rng(SEED) # Random number generator\n","tf.random.set_seed(SEED)\n","\n","################################################################################################\n","# Checkpoint parameters val_binary_io_u\n","SCORE_TO_MONITOR = 'val_binary_io_u' # Score that checkpoints monitor during training\n","SCORE_OBJECTIVE  = 'max'          # 'max' or 'min', specifies whether the objective is to maximize the score or minimize it.\n","PATIENCE_LR_REDUCE = 3\n","MIN_LR = 1e-8\n","REDUCTION_FACTOR = 0.5            # Factor which lr will be reduced with at plateau\n","\n","INITIAL_LR = 0.001"]},{"cell_type":"markdown","id":"2b874d87-e287-4dda-a0d6-79ff516adc3f","metadata":{"id":"2b874d87-e287-4dda-a0d6-79ff516adc3f","jp-MarkdownHeadingCollapsed":true},"source":["## Defining performance metrics\n","\n","Official segmentation metrics by keras: https://ks.io/api/metrics/segmentation_metrics/"]},{"cell_type":"code","execution_count":null,"id":"b8197196-670d-4e41-af29-452a87af68ba","metadata":{"id":"b8197196-670d-4e41-af29-452a87af68ba"},"outputs":[],"source":["def f1_score(y_true, y_pred): # Dice coefficient\n","    \"\"\"\n","    Calculate the F1 score, the harmonic mean of precision and recall, for binary classification.\n","\n","    Args:\n","        y_true (Tensor): True binary labels.\n","        y_pred (Tensor): Predicted probabilities.\n","\n","    Returns:\n","        float32: F1 score as a scalar.\n","    \"\"\"\n","    # True Positives: round product of y_true and y_pred\n","    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    # Actual Positives: round y_true\n","    P = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    # Recall: TP / Actual Positives\n","    recall = TP / (P + K.epsilon())\n","\n","    # Predicted Positives: round y_pred\n","    Pred_P = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    # Precision: TP / Predicted Positives\n","    precision = TP / (Pred_P + K.epsilon())\n","\n","    # F1 Score: harmonic mean of precision and recall\n","    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n","\n","# source: https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryIoU\n","iou_score_binary = tf.keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.5)\n","\n","def accuracy_score(y_true, y_pred):\n","    \"\"\"\n","    Calculate accuracy score between two binary masks.\n","    \"\"\"\n","    correct = np.sum(y_true == y_pred)  # Count correct predictions\n","    total = y_true.size  # Total number of pixels\n","    return correct / total  # Accuracy calculation\n","\n","def precision_score(groundtruth_mask, pred_mask):\n","    \"\"\"\n","    Calculate precision score between two binary masks.\n","    \"\"\"\n","    intersect = np.sum(pred_mask * groundtruth_mask)  # Calculate intersection\n","    total_pixel_pred = np.sum(pred_mask)  # Sum of predicted positives\n","    return np.mean(intersect / total_pixel_pred)  # Precision calculation\n","\n","def recall_score(groundtruth_mask, pred_mask):\n","    \"\"\"\n","    Calculate recall score between two binary masks.\n","    \"\"\"\n","    intersect = np.sum(pred_mask * groundtruth_mask)  # Calculate intersection\n","    total_pixel_truth = np.sum(groundtruth_mask)  # Sum of actual positives\n","    return np.mean(intersect / total_pixel_truth)  # Recall calculation"]},{"cell_type":"markdown","id":"ef00a1c4-00ef-4dc7-926d-638a5146c2c4","metadata":{"id":"ef00a1c4-00ef-4dc7-926d-638a5146c2c4","jp-MarkdownHeadingCollapsed":true},"source":["## Reading the data"]},{"cell_type":"code","execution_count":null,"id":"30e64959-9aaf-4396-8ca0-0378ea018ef6","metadata":{"id":"30e64959-9aaf-4396-8ca0-0378ea018ef6"},"outputs":[],"source":["# Function to read images from a directory using Pillow\n","def read_images_from_directory(directory_path):\n","    images = []\n","    for filename in sorted(os.listdir(directory_path)):\n","        # filename= filename.lower()\n","\n","        if filename.endswith(('.png', '.jpg', '.JPG' )):  # Check for image file extensions\n","            img_path = os.path.join(directory_path, filename)\n","            img = Image.open(img_path)\n","            img_array = np.array(img)  # Convert the image to a numpy array if needed\n","            if img_array is not None:\n","                images.append(img_array)\n","    return images\n","\n","# Paths to masks and original images within the dataset\n","masks_path_train = os.path.join(DATASET_PATH_TRAIN, 'data43_masks_binarised')\n","originals_path_train = os.path.join(DATASET_PATH_TRAIN, 'data43_original')\n","\n","# Read images into variables\n","x_train = read_images_from_directory(originals_path_train)  # Original images\n","y_train = read_images_from_directory(masks_path_train)  # Masks\n","\n","# Paths to masks and original images within the test dataset\n","masks_path_test = os.path.join(DATASET_PATH_TEST, 'data43_masks_binarised')\n","originals_path_test = os.path.join(DATASET_PATH_TEST, 'data43_original')\n","\n","# Read images into variables\n","x_test = read_images_from_directory(originals_path_test)  # Original images\n","y_test = read_images_from_directory(masks_path_test)  # Masks\n","\n","# Now x_train contains original images, and y_train contains mask images\n","print(f\"Loaded {len(x_train)} original images into x_train\")\n","print(f\"Loaded {len(y_train)} mask images into y_train\")\n","\n","# Similarly, for test images\n","print(f\"Loaded {len(x_test)} original images into x_test\")\n","print(f\"Loaded {len(y_test)} mask images into y_test\")"]},{"cell_type":"markdown","id":"86cb6260-a415-435f-a9eb-a85b3891ca36","metadata":{"id":"86cb6260-a415-435f-a9eb-a85b3891ca36","jp-MarkdownHeadingCollapsed":true},"source":["## Checking if the masks are correct"]},{"cell_type":"code","execution_count":null,"id":"b28d4f97-9ead-458d-bd3f-8d15c1db2754","metadata":{"id":"b28d4f97-9ead-458d-bd3f-8d15c1db2754"},"outputs":[],"source":["def has_other_values(images):\n","    \"\"\"\n","    Check if the numpy array 'images' contains any pixel values other than 0 and 255.\n","\n","    Parameters:\n","    images (list of numpy.ndarray): A list of numpy arrays, each containing image data.\n","\n","    Returns:\n","    str: A message indicating whether other pixel values are present.\n","    \"\"\"\n","    # Iterate through each image in the list\n","    for image in images:\n","        # Check if any value in the image is not equal to 0 or 255\n","        if np.any((image != 0) & (image != 255)):\n","            return \"Has other pixel values\"\n","    return \"Only contains 0 and 255\"\n","\n","\n","# Check y_train for any values other than 0 and 255\n","result_train = has_other_values(y_train)\n","print(\"y_train:\", result_train)\n","\n","# Check y_test for any values other than 0 and 255\n","result_test = has_other_values(y_test)\n","print(\"y_test:\", result_test)"]},{"cell_type":"markdown","id":"16158f56-6ad4-4bb2-8ec1-79e982705760","metadata":{"id":"16158f56-6ad4-4bb2-8ec1-79e982705760","jp-MarkdownHeadingCollapsed":true},"source":["## Visualization"]},{"cell_type":"code","execution_count":null,"id":"a5a08db5-4889-434f-a89b-de92878bb2c6","metadata":{"id":"a5a08db5-4889-434f-a89b-de92878bb2c6"},"outputs":[],"source":["indices = np.array([i for i in range(len(x_train))])\n","plot_indices = RNG.choice(indices, size=4, replace=False)\n","\n","fig, ax = plt.subplots(2,4, figsize=(10,5))\n","for i in range(len(plot_indices)):\n","    X_plot = x_train[plot_indices[i]]\n","    y_plot = y_train[plot_indices[i]]\n","    ax[0,i].imshow(X_plot)\n","    ax[1,i].imshow(y_plot, cmap = 'gray')\n","\n","ax[0,0].set_title('Sample 1', fontsize=10)\n","ax[0,1].set_title('Sample 2', fontsize=10)\n","ax[0,2].set_title('Sample 3', fontsize=10)\n","ax[0,3].set_title('Sample 4', fontsize=10)\n","\n","ax[0,0].set_ylabel('Images')\n","ax[1,0].set_ylabel('Masks')\n","\n","for axes in ax.flatten():\n","    axes.set_xticks([])\n","    axes.set_yticks([])\n","\n","fig.tight_layout()\n","# plt.show()\n","\n","if SAVE_RESULTS:\n","    # Save the plot to a PDF\n","    with PdfPages(PATH_SAVE_AUGMENT_SAMPLE) as pdf:\n","        pdf.savefig(fig)\n","        if SHOW_RESULTS:\n","            plt.show()\n","        else:\n","            plt.close()"]},{"cell_type":"code","execution_count":null,"id":"98ade0ee-fe8a-44c0-9fa9-8286fef9617e","metadata":{"id":"98ade0ee-fe8a-44c0-9fa9-8286fef9617e"},"outputs":[],"source":["positive_pixel_count = np.zeros(len(y_train))\n","#image_size = x_train.shape[1]*x_train.shape[2]\n","image_size = ORIGINAL_IMAGE_SIZE[0] * ORIGINAL_IMAGE_SIZE[1]#x_train.shape[1]*x_train.shape[2]\n","for i in tqdm(range(len(y_train))):\n","    single_y = y_train[i]\n","    positive_pixel_count[i] = np.sum(single_y != 0) / image_size * 100\n","\n","fig, ax = plt.subplots(1,1,figsize=(8,4))\n","sns.histplot(positive_pixel_count, stat='percent', ax=ax)\n","ax.set_xlabel('Percentage of positive pixels in mask')\n","ax.set_title('Label distribution plot')\n","ax.grid('on')\n","plt.show()\n","\n","if SAVE_RESULTS:\n","    # Save the plot to a PDF\n","    with PdfPages(PATH_SAVE_PIXEL_PERCENTAGE_PLOT) as pdf:\n","        pdf.savefig(fig)\n","        if SHOW_RESULTS:\n","            plt.show()\n","        else:\n","            plt.close()"]},{"cell_type":"markdown","id":"6b560e6d-8888-4f2a-8daf-e0b5340ac2f8","metadata":{"id":"6b560e6d-8888-4f2a-8daf-e0b5340ac2f8","jp-MarkdownHeadingCollapsed":true},"source":["## Preprocessing DO NOT RESIZE THE IMAGE-- IT GIVES FINE LINES IN THE OUTPUT"]},{"cell_type":"code","execution_count":null,"id":"345f792d-94b1-4954-872e-461bd735c001","metadata":{"id":"345f792d-94b1-4954-872e-461bd735c001"},"outputs":[],"source":["# # # Resizing\n","# x_train = [np.array(Image.fromarray(image).resize(RESIZE_SHAPE)) for image in x_train]\n","# y_train = [np.array(Image.fromarray(image).resize(RESIZE_SHAPE)) for image in y_train]\n","\n","# x_test = [np.array(Image.fromarray(image).resize(RESIZE_SHAPE)) for image in x_test]\n","# y_test = [np.array(Image.fromarray(image).resize(RESIZE_SHAPE)) for image in y_test]\n","\n","# Convert the list to a NumPy array\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)\n","\n","x_test = np.array(x_test)\n","y_test = np.array(y_test)\n","\n","\n","# Normalizing input between [0,1]\n","x_train = x_train.astype(\"float32\")/ np.max(x_train)\n","x_test  = x_test.astype(\"float32\")/np.max(x_test)\n","\n","y_train = y_train.astype(\"float32\")/ np.max(y_train)\n","y_test  = y_test.astype(\"float32\")/np.max(y_test)\n","\n","# Now x_train contains original images, and y_train contains mask images\n","print(f\"Loaded {len(x_train)} original images into x_train\")\n","print(f\"Loaded {len(y_train)} mask images into y_train\")\n","\n","# Similarly, for test images\n","print(f\"Loaded {len(x_test)} original images into x_test\")\n","print(f\"Loaded {len(y_test)} mask images into y_test\")"]},{"cell_type":"markdown","id":"a55684e5-7b57-43c5-a995-edd40775390d","metadata":{"id":"a55684e5-7b57-43c5-a995-edd40775390d","jp-MarkdownHeadingCollapsed":true},"source":["## Checking if the masks are correct"]},{"cell_type":"code","execution_count":null,"id":"eddf91eb-803f-4e0c-858f-c2c1922c3ebd","metadata":{"id":"eddf91eb-803f-4e0c-858f-c2c1922c3ebd"},"outputs":[],"source":["def has_other_values(images):\n","    \"\"\"\n","    Check if the numpy array 'images' contains any pixel values other than 0 and 1.\n","\n","    Parameters:\n","    images (list of numpy.ndarray): A list of numpy arrays, each containing image data.\n","\n","    Returns:\n","    str: A message indicating whether other pixel values are present.\n","    \"\"\"\n","    # Iterate through each image in the list\n","    for image in images:\n","        # Check if any value in the image is not equal to 0 or 1\n","        if np.any((image != 0) & (image != 1)):\n","            return \"Has other pixel values\"\n","    return \"Only contains 0 and 1\"\n","\n","\n","# Check y_train for any values other than 0 and 1\n","result_train = has_other_values(y_train)\n","print(\"y_train:\", result_train)\n","\n","# Check y_test for any values other than 0 and 1\n","result_test = has_other_values(y_test)\n","print(\"y_test:\", result_test)"]},{"cell_type":"markdown","id":"05782333-8336-4ad9-ae0d-ee79a4c5e6fb","metadata":{"id":"05782333-8336-4ad9-ae0d-ee79a4c5e6fb","jp-MarkdownHeadingCollapsed":true},"source":["## Visualization after pre-processing for checking condition"]},{"cell_type":"code","execution_count":null,"id":"5ac61c89-ee3a-4e49-b15e-3e1db583d80e","metadata":{"id":"5ac61c89-ee3a-4e49-b15e-3e1db583d80e"},"outputs":[],"source":["Rand_Nub = RNG.integers(1,10,5)\n","fig, ax = plt.subplots(2, 5 ,figsize=(14,5))#width, h\n","for i in range(Rand_Nub.shape[0]):\n","    ax[0, i].imshow(x_train[Rand_Nub[i]])\n","    ax[0, i].axes.xaxis.set_ticklabels([])\n","    ax[0, i].axes.yaxis.set_ticklabels([])\n","    ax[0, i].set_title('Input: '+str(i), fontsize=11)\n","    ax[0, i].axis('off')\n","\n","    ax[1, i].imshow(y_train[Rand_Nub[i]] ,cmap = 'gray')\n","    ax[1, i].axes.xaxis.set_ticklabels([])\n","    ax[1, i].axes.yaxis.set_ticklabels([])\n","    ax[1, i].set_title('Ground_Mask: '+str(i), fontsize=11)\n","    ax[1, i].axis('off')"]},{"cell_type":"markdown","id":"3631b8c9-b763-4574-8444-2034cad11cee","metadata":{"id":"3631b8c9-b763-4574-8444-2034cad11cee","jp-MarkdownHeadingCollapsed":true},"source":["## Essential functions"]},{"cell_type":"code","execution_count":null,"id":"73061e0d-ae45-45fb-9ba2-8099845466b3","metadata":{"id":"73061e0d-ae45-45fb-9ba2-8099845466b3"},"outputs":[],"source":["def fit_and_save_best_model(model_name, model, epochs=EPOCHS):\n","    ##########################################################################################################\n","    saved_best_model_name = 'best_'+model_name+'.h5'\n","\n","    model_saving_path = os.path.join(PATH_TO_SAVE_MODEL, saved_best_model_name)\n","    # Set up a model checkpoint to save the best model during training\n","    best_model_callback= ModelCheckpoint(model_saving_path,\n","                                          monitor=SCORE_TO_MONITOR,\n","                                          save_best_only=True,\n","                                          mode=SCORE_OBJECTIVE,\n","                                          verbose=1)\n","\n","    reduce_LR = ReduceLROnPlateau(\n","        factor=REDUCTION_FACTOR,      # Factor by which the learning rate will be reduced. new_lr = lr * factor\n","        patience=PATIENCE_LR_REDUCE, # original was 5      # Number of epochs with no improvement after which learning rate will be reduced.\n","        verbose=1,       # int. 0: quiet, 1: update messages.\n","        min_lr=MIN_LR   # Lower bound on the learning rate.\n","    )\n","\n","    my_callbacks = [best_model_callback , reduce_LR]\n","    ##########################################################################################################\n","\n","    start_time = time.time()\n","\n","    # Fitting the model\n","    train_history = model.fit(\n","        x_train,\n","        y_train,\n","        epochs= epochs,\n","        batch_size=BATCH_SIZE,\n","        validation_split= VALIDATION_SPLIT,\n","        callbacks=my_callbacks,\n","    )\n","    total_time = time.time() - start_time\n","\n","    return saved_best_model_name, train_history, total_time"]},{"cell_type":"code","execution_count":null,"id":"8ddd8de6-efb0-42de-9635-b95449314a68","metadata":{"id":"8ddd8de6-efb0-42de-9635-b95449314a68"},"outputs":[],"source":["def plot_training_history(training_history_object, list_of_metrics=None):\n","    \"\"\"\n","    Input:\n","        training_history_object:: Object returned by model.fit() function in keras\n","        list_of_metrics        :: A list of metrics to be plotted. Use if you only\n","                                  want to plot a subset of the total set of metrics\n","                                  in the training history object. By Default it will\n","                                  plot all of them in individual subplots.\n","    \"\"\"\n","    history_dict = training_history_object.history\n","\n","    ###################addDED NEW################################################\n","    ###Remove 'lr' and 'val_lr' keys from history_dict if they exist\n","    history_dict.pop('lr', None)\n","    history_dict.pop('val_lr', None)\n","    #############################################################################\n","\n","    if list_of_metrics is None:\n","        list_of_metrics = [key for key in list(history_dict.keys()) if 'val_' not in key]\n","\n","    # print(list_of_metrics)\n","    trainHistDF = pd.DataFrame(history_dict)\n","    # trainHistDF.head()\n","    train_keys = list_of_metrics\n","    valid_keys = ['val_' + key for key in train_keys]\n","    nr_plots = len(train_keys)\n","    fig, ax = plt.subplots(1,nr_plots,figsize=(4*nr_plots,4))\n","    for i in range(len(train_keys)):\n","        ax[i].plot(np.array(trainHistDF[train_keys[i]]), label='Training')\n","        ax[i].plot(np.array(trainHistDF[valid_keys[i]]), label='Validation')\n","        ax[i].set_xlabel('Epoch')\n","        if train_keys[i] == 'binary_io_u':\n","             ax[i].set_title('IoU')\n","        else:\n","            ax[i].set_title(train_keys[i])\n","        ax[i].grid('on')\n","        ax[i].legend()\n","    fig.tight_layout()\n","\n","\n","    if SAVE_RESULTS:\n","        # Save the plot to a PDF\n","        pdf_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_training_history.pdf\")\n","        with PdfPages(pdf_filename) as pdf:\n","            pdf.savefig(fig)\n","            if SHOW_RESULTS:\n","                plt.show()\n","            else:\n","                plt.close()"]},{"cell_type":"markdown","id":"bc3dd825-59a8-43f1-9a3c-b720ebd250dc","metadata":{"id":"bc3dd825-59a8-43f1-9a3c-b720ebd250dc"},"source":["## Models\n","### Models worked\n","- Model01: Basic basic_unet\n","- Model02: unet_vgg16 (my own custom)\n","- Model03: TransUNet\n","- Model04: DeepLab-v3Plus\n","- Model05: ResUNet\n","- Model06: UNet_with_attention\n","- Model07: Multi-resUnet\n","- Model08: Inception_resnetV2 (my own custom)\n","\n"]},{"cell_type":"markdown","id":"BFPKzpxR5aIS","metadata":{"id":"BFPKzpxR5aIS"},"source":["### UNet_with_attention--works--Ran with batch size10 (memory issues)\n","---Works properly after 10 epochs--within 5 epoch--sometimes does not show anything"]},{"cell_type":"code","execution_count":null,"id":"OfLbIpNgIimq","metadata":{"id":"OfLbIpNgIimq"},"outputs":[],"source":["def conv_block(x, num_filters):\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    return x\n","\n","def encoder_block(x, num_filters):\n","    x = conv_block(x, num_filters)\n","    p = MaxPool2D((2, 2))(x)\n","    return x, p\n","\n","def attention_gate(g, s, num_filters):\n","    Wg = Conv2D(num_filters, 1, padding=\"same\")(g)\n","    Wg = BatchNormalization()(Wg)\n","\n","    Ws = Conv2D(num_filters, 1, padding=\"same\")(s)\n","    Ws = BatchNormalization()(Ws)\n","\n","    out = Activation(\"relu\")(Wg + Ws)\n","    out = Conv2D(num_filters, 1, padding=\"same\")(out)\n","    out = Activation(\"sigmoid\")(out)\n","\n","    return out * s\n","\n","def decoder_block(x, s, num_filters):\n","    x = UpSampling2D(interpolation=\"bilinear\")(x)\n","    s = attention_gate(x, s, num_filters)\n","    x = Concatenate()([x, s])\n","    x = conv_block(x, num_filters)\n","    return x\n","\n","def UNet_with_attention():\n","    \"\"\" Inputs \"\"\"\n","\n","    ### Source: https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture/blob/main/TensorFlow/attention-unet.py\n","    inputs = Input(MODEL_INPUT_SIZE)\n","\n","    \"\"\" Encoder \"\"\"\n","    s1, p1 = encoder_block(inputs, 64)\n","    s2, p2 = encoder_block(p1, 128)\n","    s3, p3 = encoder_block(p2, 256)\n","\n","    b1 = conv_block(p3, 512)\n","\n","    \"\"\" Decoder \"\"\"\n","    d1 = decoder_block(b1, s3, 256)\n","    d2 = decoder_block(d1, s2, 128)\n","    d3 = decoder_block(d2, s1, 64)\n","\n","    \"\"\" Outputs \"\"\"\n","    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d3)\n","\n","    \"\"\" Model \"\"\"\n","    model = Model(inputs, outputs, name=\"Attention-UNET\")\n","    optimizer = Adam(learning_rate=INITIAL_LR)\n","    model.compile(loss='binary_crossentropy',\n","                  metrics=['accuracy', f1_score, iou_score_binary],\n","                  optimizer=optimizer)\n","\n","    return model"]},{"cell_type":"markdown","id":"c8391326-d459-4214-ad6c-efd1d12ad54a","metadata":{"id":"c8391326-d459-4214-ad6c-efd1d12ad54a"},"source":["## Train and Results"]},{"cell_type":"code","execution_count":null,"id":"3d3e72d6-6137-46fe-9a41-418999643dbb","metadata":{"id":"3d3e72d6-6137-46fe-9a41-418999643dbb"},"outputs":[],"source":["# model= get_basic_unet() ## Model1\n","# model= get_unet_vgg16() ## Model2\n","# model= get_TransUNet() ## Model3\n","# model= get_DeepLabV3Plus() ## Model4\n","# model = get_ResUNet_v3() ## Model5\n","model = UNet_with_attention() ## Model6\n","# model = get_multiresunet() ## Model7\n","# model = get_unet_InceptionResNetV2() ## Model8\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"e297b3da-e42c-4ee2-8dda-43cd0016bf00","metadata":{"id":"e297b3da-e42c-4ee2-8dda-43cd0016bf00"},"outputs":[],"source":["# training the model and saving the best model as a check point\n","best_model_name, train_history, total_time = fit_and_save_best_model(model_name, model)"]},{"cell_type":"code","execution_count":null,"id":"641b7d4d-76cc-494c-a44b-de0ae483a4f0","metadata":{"id":"641b7d4d-76cc-494c-a44b-de0ae483a4f0"},"outputs":[],"source":["# Saving the time to be reused\n","time_data = {\n","    \"model_name\": [model_name],\n","    \"run_time\": [total_time]\n","}\n","\n","# Convert the dictionary to a pandas DataFrame\n","time_df = pd.DataFrame(time_data)\n","\n","# Save the DataFrame to a CSV file\n","time_df.to_csv(PATH_SAVE_TIME, index=False)"]},{"cell_type":"code","execution_count":null,"id":"a26d84ec-2973-4715-9bc2-7c456050d6f1","metadata":{"id":"a26d84ec-2973-4715-9bc2-7c456050d6f1"},"outputs":[],"source":["# Saving the history as csv file to be reused\n","history_df = pd.DataFrame(train_history.history)\n","history_df.to_csv(PATH_SAVE_HISTORY, index=False)"]},{"cell_type":"code","execution_count":null,"id":"182eead8-6f8e-4534-9666-1a54c3d82c59","metadata":{"id":"182eead8-6f8e-4534-9666-1a54c3d82c59"},"outputs":[],"source":["# plotting train history\n","plot_training_history(train_history)"]},{"cell_type":"markdown","id":"58066d61-295d-4a1e-bd34-35fad6fddeb6","metadata":{"id":"58066d61-295d-4a1e-bd34-35fad6fddeb6"},"source":["## Loading the best model"]},{"cell_type":"code","execution_count":null,"id":"2efedf22-df76-4922-b09c-6357388b6458","metadata":{"id":"2efedf22-df76-4922-b09c-6357388b6458"},"outputs":[],"source":["##Now, load the best model\n","best_model = ks.models.load_model(os.path.join(PATH_TO_SAVE_MODEL, best_model_name),\n","                                  custom_objects={'f1_score': f1_score,\n","                                                  'binary_io_u':iou_score_binary})\n","\n","# best_model =model"]},{"cell_type":"markdown","id":"5b6e079b-b8bf-4be8-97d5-bcbc737b4f75","metadata":{"id":"5b6e079b-b8bf-4be8-97d5-bcbc737b4f75"},"source":["## Visualize model predictions"]},{"cell_type":"code","execution_count":null,"id":"0e84b3ee-95d2-46ac-aee4-77e8515e600a","metadata":{"id":"0e84b3ee-95d2-46ac-aee4-77e8515e600a"},"outputs":[],"source":["# Get predictions from the model\n","predictions = best_model.predict(x_test, verbose=1)\n","\n","USER_DETERMINED_THRESHOLD = 0.5\n","thresholded_predictions  = (predictions  >= USER_DETERMINED_THRESHOLD)\n","# Removing the color channel\n","thresholded_predictions_without_color_channel = np.squeeze(thresholded_predictions, axis=-1)"]},{"cell_type":"code","execution_count":null,"id":"958dd841-1d93-4d10-9bb0-293483adb8d7","metadata":{"id":"958dd841-1d93-4d10-9bb0-293483adb8d7"},"outputs":[],"source":["############################################################################################################]\n","\n","# Define the number of images to visualize\n","num_images = 4\n","\n","# Create a figure with subplots\n","fig, axes = plt.subplots(num_images, 4, figsize=(12, 3 * num_images))\n","\n","sample_indices = [0, 13, 4, 18]  #\n","# for i in range(num_images):\n","for i, chosen_index in enumerate(sample_indices):\n","    # Display original image\n","    axes[i, 0].imshow(x_test[chosen_index])\n","    axes[i, 0].set_title('Original Image ('+ str(i+1)+\")\", fontsize=11)\n","\n","    # Display ground truth mask\n","    axes[i, 1].imshow(y_test[chosen_index], cmap='gray')\n","    axes[i, 1].set_title('Ground truth mask ('+ str(i+1)+\")\", fontsize=11)\n","\n","    # Display predicted mask\n","    # axes[i, 2].imshow(thresholded_predictions[i], cmap='gray')\n","    axes[i, 2].imshow(thresholded_predictions[chosen_index], cmap='gray')\n","    axes[i, 2].set_title('Thresholded predicted mask ('+ str(i+1)+\")\", fontsize=11)\n","\n","        # Display predicted mask\n","    axes[i, 3].imshow(predictions[chosen_index], cmap='gray')\n","    axes[i, 3].set_title('Initial predicted mask ('+ str(i+1)+\")\", fontsize=11)\n","\n","\n","    # Turn off axis labels\n","    for ax in axes[i]:\n","        ax.axis('off')\n","\n","plt.tight_layout(pad=1.0, w_pad=1.5, h_pad=1.00)\n","# plt.tight_layout()\n","# plt.show()\n","\n","# Save the plot to a PDF\n","if SAVE_RESULTS:\n","\n","    pdf_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_prediction_sample01.pdf\")\n","    with PdfPages(pdf_filename) as pdf:\n","        pdf.savefig()  # saves the current figure into a pdf page\n","        # plt.close()\n","        if SHOW_RESULTS:\n","            plt.show()\n","        else:\n","            plt.close()"]},{"cell_type":"code","execution_count":null,"id":"3be982e8-74cc-4c9c-b17d-ad79ef022637","metadata":{"id":"3be982e8-74cc-4c9c-b17d-ad79ef022637"},"outputs":[],"source":["def plot_samples(X, Y, predictions, sample_indices):\n","    \"\"\"\n","    Plots the original image, prediction, and ground truth for given samples, with titles for each row.\n","\n","    Parameters:\n","    - X: the test set images.\n","    - Y: the ground truth labels for the test set.\n","    - predictions: the model's predictions.\n","    - sample_indices: list of indices of the samples to plot.\n","    - SAVE_RESULTS: Boolean indicating if the results should be saved (default False).\n","    - PATH_TO_SAVE_RESULT: Path where the plot should be saved if SAVE_RESULTS is True.\n","    - model_name: Name of the model to use in the filename when saving results.\n","    \"\"\"\n","    num_samples = len(sample_indices)\n","    fig, axes = plt.subplots(num_samples, 3, figsize=(9, num_samples * 3))  # Adjusted figsize for 3 columns\n","    plt.subplots_adjust(0, 0, 1, 1, hspace=0.1, wspace=0.1)\n","\n","    # Titles for the first row\n","    titles = ['Original', 'Prediction (red for high probabilities)', 'Ground Truth']\n","    side_titles = ['Sample 1', 'Sample 2', 'Sample 3']  # Side titles for each sample\n","\n","    for i, sample_index in enumerate(sample_indices):\n","        data = [\n","            X[sample_index, ...],\n","            predictions[sample_index, ..., 0],\n","            Y[sample_index, ...]\n","        ]\n","\n","        cmaps = [None, plt.cm.jet, plt.cm.jet]\n","\n","        for j, (datum, cmap) in enumerate(zip(data, cmaps)):\n","            ax = axes[i, j] if num_samples > 1 else axes[j]\n","            mesh = ax.pcolormesh(datum, cmap=cmap)\n","            if i == 0:\n","                ax.set_title(titles[j], fontsize=11)\n","            if j == 0:\n","                ax.set_ylabel(side_titles[i], fontsize=11)\n","            # ax.axis('off')\n","\n","    for ax in axes.flatten():\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","\n","    fig.tight_layout()\n","\n","    if SAVE_RESULTS:\n","        pdf_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_prediction_sample02_color.pdf\")\n","        with PdfPages(pdf_filename) as pdf:\n","            pdf.savefig()  # saves the current figure into a pdf page\n","            # plt.close()\n","            if SHOW_RESULTS:\n","                plt.show()\n","            else:\n","                plt.close()\n","\n","sample_indices = [0, 13, 4]  # Indices of the samples you want to plot\n","plot_samples(x_test, y_test, predictions, sample_indices)"]},{"cell_type":"code","execution_count":null,"id":"1fff1a1a-a710-477c-b536-05468c047ed3","metadata":{"id":"1fff1a1a-a710-477c-b536-05468c047ed3"},"outputs":[],"source":["indices = np.array([i for i in range(len(x_test))])\n","rand_X_indices = RNG.choice(indices, size=4, replace=False)\n","rand_X = np.array([x_test[idx] for idx in rand_X_indices])\n","rand_y = np.array([y_test[idx] for idx in rand_X_indices])\n","rand_y_predictions = np.array([thresholded_predictions[idx] for idx in rand_X_indices])\n","\n","fig, ax = plt.subplots(3,4, figsize=(10,7.5))\n","for i in range(4):\n","    ax[0,i].imshow(rand_X[i])\n","    ax[1,i].imshow(rand_y_predictions[i], cmap='gray')\n","    ax[2,i].imshow(rand_y[i], cmap='gray')\n","\n","ax[0,0].set_title('Sample 1', fontsize=11)\n","ax[0,1].set_title('Sample 2', fontsize=11)\n","ax[0,2].set_title('Sample 3', fontsize=11)\n","ax[0,3].set_title('Sample 4', fontsize=11)\n","\n","ax[0,0].set_ylabel('Images')\n","ax[1,0].set_ylabel('Predicted masks')\n","ax[2,0].set_ylabel('Ground truth masks')\n","\n","for axes in ax.flatten():\n","    axes.set_xticks([])\n","    axes.set_yticks([])\n","\n","fig.tight_layout()\n","# plt.show()\n","\n","# Save the plot to a PDF\n","if SAVE_RESULTS:\n","    pdf_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_prediction_sample03.pdf\")\n","    with PdfPages(pdf_filename) as pdf:\n","        pdf.savefig()  # saves the current figure into a pdf page\n","        # plt.close()\n","        if SHOW_RESULTS:\n","            plt.show()\n","        else:\n","            plt.close()"]},{"cell_type":"markdown","id":"1bec66ee-9e70-46ae-9182-b2e80807bf55","metadata":{"id":"1bec66ee-9e70-46ae-9182-b2e80807bf55","jp-MarkdownHeadingCollapsed":true},"source":["## Test evaluations"]},{"cell_type":"code","execution_count":null,"id":"6a456984-9899-49b4-80a5-1caa22a40247","metadata":{"id":"6a456984-9899-49b4-80a5-1caa22a40247"},"outputs":[],"source":["def calculate_test_performance_metrics_all(y_true, y_pred, test_loss ):\n","\n","    y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\n","    y_pred_tensor = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n","\n","    accuracy_value = accuracy_score(y_true, y_pred)\n","    precision_value = precision_score(y_true, y_pred)\n","    recall_value = recall_score(y_true, y_pred)\n","    f1_score_value = f1_score(y_test_tensor, y_pred_tensor).numpy()\n","\n","    iou_score_binary.update_state(y_test, y_pred)\n","    iou_binary = iou_score_binary.result().numpy()\n","\n","    # Create a dictionary to hold the metrics\n","    test_results = {\n","        'Model Name': model_name,\n","        'Loss': test_loss,\n","        'Accuracy': accuracy_value,\n","        'Precision': precision_value,\n","        'Recall': recall_value,\n","        'F1-Score': f1_score_value,\n","        'IoU': iou_binary\n","    }\n","\n","        # Convert the dictionary to a DataFrame\n","    report_df = pd.DataFrame([test_results])\n","\n","    if SHOW_RESULTS:\n","        display(report_df)\n","\n","    if SAVE_RESULTS:\n","        path_to_save = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_model_all_test_performance.csv\")\n","        # Save the DataFrame to a CSV file\n","        report_df.to_csv(path_to_save , index=False)"]},{"cell_type":"code","execution_count":null,"id":"9ff57555-1814-4de7-956b-603a5f9d3919","metadata":{"id":"9ff57555-1814-4de7-956b-603a5f9d3919"},"outputs":[],"source":["test_loss, test_accuracy, test_f1_score,  test_iou=best_model.evaluate(x_test, y_test)"]},{"cell_type":"code","execution_count":null,"id":"d94bbbfb-6ebb-445c-ab42-90b95fb4f324","metadata":{"id":"d94bbbfb-6ebb-445c-ab42-90b95fb4f324"},"outputs":[],"source":["calculate_test_performance_metrics_all(y_true=y_test,\n","                                       y_pred=thresholded_predictions_without_color_channel,\n","                                       test_loss=test_loss)"]},{"cell_type":"code","execution_count":null,"id":"3389b83b-7df1-4f3e-b14d-77f7e7ed710f","metadata":{"id":"3389b83b-7df1-4f3e-b14d-77f7e7ed710f"},"outputs":[],"source":["def calculate_confusion_matrix(y_true, y_pred):\n","    \"\"\"\n","    Calculate the confusion matrix components for a segmentation task.\n","\n","    Args:\n","        y_true (numpy.ndarray): The ground truth binary mask.\n","        y_pred (numpy.ndarray): The predicted binary mask.\n","\n","    Returns:\n","        tuple: A tuple containing the counts of TP, FP, FN, TN.\n","    \"\"\"\n","    TP = np.sum((y_true == 1) & (y_pred == 1))\n","    FP = np.sum((y_true == 0) & (y_pred == 1))\n","    FN = np.sum((y_true == 1) & (y_pred == 0))\n","    TN = np.sum((y_true == 0) & (y_pred == 0))\n","\n","    return TP, FP, FN, TN\n","\n","\n","def plot_confusion_matrix(y_true, y_pred, model_name=\"default_name\"): ## WORKS\n","    \"\"\"\n","    Manually plot a confusion matrix for the results of a segmentation task, ensuring all elements are visible,\n","    with dividing lines between the rows and columns.\n","\n","    Args:\n","        y_true (numpy.ndarray): The ground truth binary mask.\n","        y_pred (numpy.ndarray): The predicted binary mask.\n","        model_name (str): Optional. The name of the model for titling the plot.\n","        SAVE_RESULTS (bool): Optional. If True, saves the plot as a PNG file.\n","    \"\"\"\n","\n","    # Calculate the confusion matrix components\n","    TP, FP, FN, TN = calculate_confusion_matrix(y_true, y_pred)\n","\n","    # Create the confusion matrix array\n","    confusion_matrix = np.array([[TP, FP], [FN, TN]])\n","\n","    fig, ax = plt.subplots(figsize=(3, 3))\n","    cmap = plt.cm.Greens\n","    ax.imshow(np.zeros_like(confusion_matrix), cmap=cmap, vmin=0, vmax=1)\n","\n","    # Annotate the cells with the confusion matrix counts\n","    for (i, j), val in np.ndenumerate(confusion_matrix):\n","        ax.text(j, i, f'{val}', ha='center', va='center', color='black', fontsize=11)\n","\n","    # Set tick labels\n","    ax.set_xticks([0, 1])\n","    ax.set_yticks([-0.2, 0.6])\n","    ax.set_xticklabels(['Disease', 'Background'], fontsize=11)\n","    ax.set_yticklabels(['Disease', 'Background'], fontsize=11)\n","\n","    # Remove the ticks while keeping the labels\n","    ax.tick_params(axis='x', which='both', length=0) # Removes x-axis ticks\n","    ax.tick_params(axis='y', which='both', length=0) # Removes y-axis ticks\n","\n","    # Rotate y-axis labels\n","    plt.yticks(rotation=90)\n","\n","    # Set axis labels and title\n","    ax.set_xlabel('Predicted labels')\n","    ax.set_ylabel('True labels')\n","\n","    # adding borders to the plot\n","    for spine in ax.spines.values():\n","        spine.set_edgecolor('black')\n","        spine.set_linewidth(1)\n","\n","    # Draw dividing lines between the rows and columns\n","    ax.axhline(y=0.5, color='black', linewidth=1)\n","    ax.axvline(x=0.5, color='black', linewidth=1)\n","\n","    plt.tight_layout()\n","\n","    # Save the plot to a PDF\n","    if SAVE_RESULTS:\n","        pdf_filename = os.path.join(PATH_TO_SAVE_RESULT, f\"{model_name}_confusion_matrix.pdf\")\n","        with PdfPages(pdf_filename) as pdf:\n","            pdf.savefig()  # saves the current figure into a pdf page\n","            # plt.close()\n","            if SHOW_RESULTS:\n","                plt.show()\n","            else:\n","                plt.close()"]},{"cell_type":"code","execution_count":null,"id":"a8333f23-92d1-4a71-8cf1-f434e3bbf7a5","metadata":{"id":"a8333f23-92d1-4a71-8cf1-f434e3bbf7a5"},"outputs":[],"source":["plot_confusion_matrix(y_true=y_test,\n","                      y_pred=thresholded_predictions_without_color_channel,\n","                      model_name=model_name)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}